{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 7360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005434782608695652,
      "grad_norm": 2.012913942337036,
      "learning_rate": 4.993885869565218e-05,
      "loss": 4.8361,
      "step": 10
    },
    {
      "epoch": 0.010869565217391304,
      "grad_norm": 3.2163538932800293,
      "learning_rate": 4.9870923913043485e-05,
      "loss": 4.7244,
      "step": 20
    },
    {
      "epoch": 0.016304347826086956,
      "grad_norm": 3.72782301902771,
      "learning_rate": 4.980298913043479e-05,
      "loss": 4.5609,
      "step": 30
    },
    {
      "epoch": 0.021739130434782608,
      "grad_norm": 3.9216866493225098,
      "learning_rate": 4.973505434782609e-05,
      "loss": 4.4289,
      "step": 40
    },
    {
      "epoch": 0.02717391304347826,
      "grad_norm": 4.401301383972168,
      "learning_rate": 4.96671195652174e-05,
      "loss": 4.2379,
      "step": 50
    },
    {
      "epoch": 0.03260869565217391,
      "grad_norm": 4.154626846313477,
      "learning_rate": 4.95991847826087e-05,
      "loss": 4.1339,
      "step": 60
    },
    {
      "epoch": 0.03804347826086957,
      "grad_norm": 4.712050437927246,
      "learning_rate": 4.953125e-05,
      "loss": 4.0769,
      "step": 70
    },
    {
      "epoch": 0.043478260869565216,
      "grad_norm": 4.464074611663818,
      "learning_rate": 4.946331521739131e-05,
      "loss": 3.8199,
      "step": 80
    },
    {
      "epoch": 0.04891304347826087,
      "grad_norm": 4.983031272888184,
      "learning_rate": 4.939538043478261e-05,
      "loss": 3.5473,
      "step": 90
    },
    {
      "epoch": 0.05434782608695652,
      "grad_norm": 4.595382213592529,
      "learning_rate": 4.932744565217391e-05,
      "loss": 3.3776,
      "step": 100
    },
    {
      "epoch": 0.059782608695652176,
      "grad_norm": 5.00801420211792,
      "learning_rate": 4.9259510869565215e-05,
      "loss": 3.2631,
      "step": 110
    },
    {
      "epoch": 0.06521739130434782,
      "grad_norm": 5.456506252288818,
      "learning_rate": 4.9191576086956524e-05,
      "loss": 2.9074,
      "step": 120
    },
    {
      "epoch": 0.07065217391304347,
      "grad_norm": 5.10790491104126,
      "learning_rate": 4.9123641304347826e-05,
      "loss": 2.8038,
      "step": 130
    },
    {
      "epoch": 0.07608695652173914,
      "grad_norm": 5.083742141723633,
      "learning_rate": 4.9055706521739134e-05,
      "loss": 2.5755,
      "step": 140
    },
    {
      "epoch": 0.08152173913043478,
      "grad_norm": 5.217650890350342,
      "learning_rate": 4.8987771739130436e-05,
      "loss": 2.5686,
      "step": 150
    },
    {
      "epoch": 0.08695652173913043,
      "grad_norm": 5.028913497924805,
      "learning_rate": 4.8919836956521745e-05,
      "loss": 2.4268,
      "step": 160
    },
    {
      "epoch": 0.09239130434782608,
      "grad_norm": 4.428904056549072,
      "learning_rate": 4.8851902173913046e-05,
      "loss": 2.2914,
      "step": 170
    },
    {
      "epoch": 0.09782608695652174,
      "grad_norm": 4.571587085723877,
      "learning_rate": 4.8783967391304355e-05,
      "loss": 1.9667,
      "step": 180
    },
    {
      "epoch": 0.10326086956521739,
      "grad_norm": 4.766147613525391,
      "learning_rate": 4.871603260869566e-05,
      "loss": 1.8834,
      "step": 190
    },
    {
      "epoch": 0.10869565217391304,
      "grad_norm": 4.450499057769775,
      "learning_rate": 4.864809782608696e-05,
      "loss": 1.7769,
      "step": 200
    },
    {
      "epoch": 0.11413043478260869,
      "grad_norm": 5.33736515045166,
      "learning_rate": 4.858016304347826e-05,
      "loss": 1.7375,
      "step": 210
    },
    {
      "epoch": 0.11956521739130435,
      "grad_norm": 4.5442118644714355,
      "learning_rate": 4.851222826086957e-05,
      "loss": 1.7458,
      "step": 220
    },
    {
      "epoch": 0.125,
      "grad_norm": 3.8696506023406982,
      "learning_rate": 4.844429347826087e-05,
      "loss": 1.4158,
      "step": 230
    },
    {
      "epoch": 0.13043478260869565,
      "grad_norm": 5.144765377044678,
      "learning_rate": 4.837635869565217e-05,
      "loss": 1.3597,
      "step": 240
    },
    {
      "epoch": 0.1358695652173913,
      "grad_norm": 3.4425172805786133,
      "learning_rate": 4.830842391304348e-05,
      "loss": 1.3978,
      "step": 250
    },
    {
      "epoch": 0.14130434782608695,
      "grad_norm": 4.25739049911499,
      "learning_rate": 4.824048913043478e-05,
      "loss": 1.2276,
      "step": 260
    },
    {
      "epoch": 0.14673913043478262,
      "grad_norm": 3.4784200191497803,
      "learning_rate": 4.8172554347826085e-05,
      "loss": 1.2858,
      "step": 270
    },
    {
      "epoch": 0.15217391304347827,
      "grad_norm": 3.1997439861297607,
      "learning_rate": 4.8104619565217393e-05,
      "loss": 1.0898,
      "step": 280
    },
    {
      "epoch": 0.15760869565217392,
      "grad_norm": 3.75978684425354,
      "learning_rate": 4.8036684782608695e-05,
      "loss": 1.0035,
      "step": 290
    },
    {
      "epoch": 0.16304347826086957,
      "grad_norm": 4.067617416381836,
      "learning_rate": 4.7968750000000004e-05,
      "loss": 0.9068,
      "step": 300
    },
    {
      "epoch": 0.16847826086956522,
      "grad_norm": 3.035022258758545,
      "learning_rate": 4.790081521739131e-05,
      "loss": 0.8457,
      "step": 310
    },
    {
      "epoch": 0.17391304347826086,
      "grad_norm": 2.9818482398986816,
      "learning_rate": 4.7832880434782614e-05,
      "loss": 0.7754,
      "step": 320
    },
    {
      "epoch": 0.1793478260869565,
      "grad_norm": 3.176626443862915,
      "learning_rate": 4.7764945652173916e-05,
      "loss": 0.804,
      "step": 330
    },
    {
      "epoch": 0.18478260869565216,
      "grad_norm": 3.438930034637451,
      "learning_rate": 4.769701086956522e-05,
      "loss": 0.8479,
      "step": 340
    },
    {
      "epoch": 0.19021739130434784,
      "grad_norm": 4.941937446594238,
      "learning_rate": 4.7629076086956526e-05,
      "loss": 0.7175,
      "step": 350
    },
    {
      "epoch": 0.1956521739130435,
      "grad_norm": 2.5581536293029785,
      "learning_rate": 4.756114130434783e-05,
      "loss": 0.7132,
      "step": 360
    },
    {
      "epoch": 0.20108695652173914,
      "grad_norm": 3.054905414581299,
      "learning_rate": 4.749320652173913e-05,
      "loss": 0.5868,
      "step": 370
    },
    {
      "epoch": 0.20652173913043478,
      "grad_norm": 2.2133400440216064,
      "learning_rate": 4.742527173913044e-05,
      "loss": 0.6099,
      "step": 380
    },
    {
      "epoch": 0.21195652173913043,
      "grad_norm": 3.3795979022979736,
      "learning_rate": 4.735733695652174e-05,
      "loss": 0.5424,
      "step": 390
    },
    {
      "epoch": 0.21739130434782608,
      "grad_norm": 3.4488914012908936,
      "learning_rate": 4.728940217391304e-05,
      "loss": 0.555,
      "step": 400
    },
    {
      "epoch": 0.22282608695652173,
      "grad_norm": 2.8782477378845215,
      "learning_rate": 4.722146739130435e-05,
      "loss": 0.4808,
      "step": 410
    },
    {
      "epoch": 0.22826086956521738,
      "grad_norm": 3.6692922115325928,
      "learning_rate": 4.715353260869565e-05,
      "loss": 0.4841,
      "step": 420
    },
    {
      "epoch": 0.23369565217391305,
      "grad_norm": 1.8971890211105347,
      "learning_rate": 4.708559782608696e-05,
      "loss": 0.4443,
      "step": 430
    },
    {
      "epoch": 0.2391304347826087,
      "grad_norm": 2.3260304927825928,
      "learning_rate": 4.701766304347826e-05,
      "loss": 0.4128,
      "step": 440
    },
    {
      "epoch": 0.24456521739130435,
      "grad_norm": 2.4332449436187744,
      "learning_rate": 4.694972826086957e-05,
      "loss": 0.4734,
      "step": 450
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.3990566730499268,
      "learning_rate": 4.6881793478260874e-05,
      "loss": 0.3874,
      "step": 460
    },
    {
      "epoch": 0.2554347826086957,
      "grad_norm": 1.7778210639953613,
      "learning_rate": 4.6813858695652175e-05,
      "loss": 0.3292,
      "step": 470
    },
    {
      "epoch": 0.2608695652173913,
      "grad_norm": 3.2310726642608643,
      "learning_rate": 4.6745923913043484e-05,
      "loss": 0.3032,
      "step": 480
    },
    {
      "epoch": 0.266304347826087,
      "grad_norm": 1.7557669878005981,
      "learning_rate": 4.6677989130434786e-05,
      "loss": 0.2803,
      "step": 490
    },
    {
      "epoch": 0.2717391304347826,
      "grad_norm": 1.5304019451141357,
      "learning_rate": 4.661005434782609e-05,
      "loss": 0.2433,
      "step": 500
    },
    {
      "epoch": 0.27717391304347827,
      "grad_norm": 1.4852569103240967,
      "learning_rate": 4.6542119565217396e-05,
      "loss": 0.2654,
      "step": 510
    },
    {
      "epoch": 0.2826086956521739,
      "grad_norm": 1.3341928720474243,
      "learning_rate": 4.64741847826087e-05,
      "loss": 0.2658,
      "step": 520
    },
    {
      "epoch": 0.28804347826086957,
      "grad_norm": 1.4664645195007324,
      "learning_rate": 4.640625e-05,
      "loss": 0.214,
      "step": 530
    },
    {
      "epoch": 0.29347826086956524,
      "grad_norm": 2.8378043174743652,
      "learning_rate": 4.633831521739131e-05,
      "loss": 0.2451,
      "step": 540
    },
    {
      "epoch": 0.29891304347826086,
      "grad_norm": 2.474261999130249,
      "learning_rate": 4.627038043478261e-05,
      "loss": 0.2073,
      "step": 550
    },
    {
      "epoch": 0.30434782608695654,
      "grad_norm": 1.5876877307891846,
      "learning_rate": 4.620244565217391e-05,
      "loss": 0.1545,
      "step": 560
    },
    {
      "epoch": 0.30978260869565216,
      "grad_norm": 1.4215388298034668,
      "learning_rate": 4.613451086956522e-05,
      "loss": 0.1657,
      "step": 570
    },
    {
      "epoch": 0.31521739130434784,
      "grad_norm": 2.7405176162719727,
      "learning_rate": 4.606657608695652e-05,
      "loss": 0.2265,
      "step": 580
    },
    {
      "epoch": 0.32065217391304346,
      "grad_norm": 0.8283782601356506,
      "learning_rate": 4.599864130434783e-05,
      "loss": 0.1642,
      "step": 590
    },
    {
      "epoch": 0.32608695652173914,
      "grad_norm": 3.206301689147949,
      "learning_rate": 4.593070652173913e-05,
      "loss": 0.2039,
      "step": 600
    },
    {
      "epoch": 0.33152173913043476,
      "grad_norm": 0.82692551612854,
      "learning_rate": 4.586277173913044e-05,
      "loss": 0.1579,
      "step": 610
    },
    {
      "epoch": 0.33695652173913043,
      "grad_norm": 0.9537339210510254,
      "learning_rate": 4.579483695652174e-05,
      "loss": 0.1311,
      "step": 620
    },
    {
      "epoch": 0.3423913043478261,
      "grad_norm": 0.8648004531860352,
      "learning_rate": 4.5726902173913045e-05,
      "loss": 0.1263,
      "step": 630
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 0.7734028100967407,
      "learning_rate": 4.5658967391304354e-05,
      "loss": 0.167,
      "step": 640
    },
    {
      "epoch": 0.3532608695652174,
      "grad_norm": 1.0204066038131714,
      "learning_rate": 4.5591032608695655e-05,
      "loss": 0.1109,
      "step": 650
    },
    {
      "epoch": 0.358695652173913,
      "grad_norm": 1.5715734958648682,
      "learning_rate": 4.552309782608696e-05,
      "loss": 0.101,
      "step": 660
    },
    {
      "epoch": 0.3641304347826087,
      "grad_norm": 2.5773916244506836,
      "learning_rate": 4.545516304347826e-05,
      "loss": 0.1245,
      "step": 670
    },
    {
      "epoch": 0.3695652173913043,
      "grad_norm": 0.5021970868110657,
      "learning_rate": 4.538722826086957e-05,
      "loss": 0.0756,
      "step": 680
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.025599718093872,
      "learning_rate": 4.531929347826087e-05,
      "loss": 0.0745,
      "step": 690
    },
    {
      "epoch": 0.3804347826086957,
      "grad_norm": 0.8868846893310547,
      "learning_rate": 4.525135869565217e-05,
      "loss": 0.0634,
      "step": 700
    },
    {
      "epoch": 0.3858695652173913,
      "grad_norm": 0.8047454357147217,
      "learning_rate": 4.518342391304348e-05,
      "loss": 0.061,
      "step": 710
    },
    {
      "epoch": 0.391304347826087,
      "grad_norm": 0.4420149326324463,
      "learning_rate": 4.511548913043478e-05,
      "loss": 0.0812,
      "step": 720
    },
    {
      "epoch": 0.3967391304347826,
      "grad_norm": 0.29529476165771484,
      "learning_rate": 4.504755434782609e-05,
      "loss": 0.0639,
      "step": 730
    },
    {
      "epoch": 0.40217391304347827,
      "grad_norm": 3.005493640899658,
      "learning_rate": 4.49796195652174e-05,
      "loss": 0.0866,
      "step": 740
    },
    {
      "epoch": 0.4076086956521739,
      "grad_norm": 2.920222043991089,
      "learning_rate": 4.49116847826087e-05,
      "loss": 0.0905,
      "step": 750
    },
    {
      "epoch": 0.41304347826086957,
      "grad_norm": 0.3003939986228943,
      "learning_rate": 4.484375e-05,
      "loss": 0.1332,
      "step": 760
    },
    {
      "epoch": 0.41847826086956524,
      "grad_norm": 2.431537389755249,
      "learning_rate": 4.477581521739131e-05,
      "loss": 0.0797,
      "step": 770
    },
    {
      "epoch": 0.42391304347826086,
      "grad_norm": 0.8407803773880005,
      "learning_rate": 4.470788043478261e-05,
      "loss": 0.0714,
      "step": 780
    },
    {
      "epoch": 0.42934782608695654,
      "grad_norm": 3.2891688346862793,
      "learning_rate": 4.4639945652173915e-05,
      "loss": 0.0815,
      "step": 790
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 0.31309422850608826,
      "learning_rate": 4.4572010869565216e-05,
      "loss": 0.0963,
      "step": 800
    },
    {
      "epoch": 0.44021739130434784,
      "grad_norm": 1.7877776622772217,
      "learning_rate": 4.4504076086956525e-05,
      "loss": 0.1225,
      "step": 810
    },
    {
      "epoch": 0.44565217391304346,
      "grad_norm": 0.30239561200141907,
      "learning_rate": 4.443614130434783e-05,
      "loss": 0.0422,
      "step": 820
    },
    {
      "epoch": 0.45108695652173914,
      "grad_norm": 0.40516993403434753,
      "learning_rate": 4.436820652173913e-05,
      "loss": 0.0483,
      "step": 830
    },
    {
      "epoch": 0.45652173913043476,
      "grad_norm": 2.76932954788208,
      "learning_rate": 4.430027173913044e-05,
      "loss": 0.1228,
      "step": 840
    },
    {
      "epoch": 0.46195652173913043,
      "grad_norm": 0.27266624569892883,
      "learning_rate": 4.423233695652174e-05,
      "loss": 0.0633,
      "step": 850
    },
    {
      "epoch": 0.4673913043478261,
      "grad_norm": 2.4691896438598633,
      "learning_rate": 4.416440217391304e-05,
      "loss": 0.1008,
      "step": 860
    },
    {
      "epoch": 0.47282608695652173,
      "grad_norm": 2.7958590984344482,
      "learning_rate": 4.409646739130435e-05,
      "loss": 0.0592,
      "step": 870
    },
    {
      "epoch": 0.4782608695652174,
      "grad_norm": 2.453529119491577,
      "learning_rate": 4.402853260869566e-05,
      "loss": 0.0835,
      "step": 880
    },
    {
      "epoch": 0.483695652173913,
      "grad_norm": 0.283934623003006,
      "learning_rate": 4.396059782608696e-05,
      "loss": 0.079,
      "step": 890
    },
    {
      "epoch": 0.4891304347826087,
      "grad_norm": 1.332332968711853,
      "learning_rate": 4.389266304347826e-05,
      "loss": 0.0506,
      "step": 900
    },
    {
      "epoch": 0.4945652173913043,
      "grad_norm": 2.3742117881774902,
      "learning_rate": 4.382472826086957e-05,
      "loss": 0.0905,
      "step": 910
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2048591673374176,
      "learning_rate": 4.375679347826087e-05,
      "loss": 0.0839,
      "step": 920
    },
    {
      "epoch": 0.5054347826086957,
      "grad_norm": 0.24185410141944885,
      "learning_rate": 4.3688858695652174e-05,
      "loss": 0.0788,
      "step": 930
    },
    {
      "epoch": 0.5108695652173914,
      "grad_norm": 0.3456937372684479,
      "learning_rate": 4.362092391304348e-05,
      "loss": 0.0792,
      "step": 940
    },
    {
      "epoch": 0.5163043478260869,
      "grad_norm": 2.3170673847198486,
      "learning_rate": 4.3552989130434784e-05,
      "loss": 0.1002,
      "step": 950
    },
    {
      "epoch": 0.5217391304347826,
      "grad_norm": 0.21163621544837952,
      "learning_rate": 4.3485054347826086e-05,
      "loss": 0.066,
      "step": 960
    },
    {
      "epoch": 0.5271739130434783,
      "grad_norm": 1.6049522161483765,
      "learning_rate": 4.3417119565217395e-05,
      "loss": 0.0609,
      "step": 970
    },
    {
      "epoch": 0.532608695652174,
      "grad_norm": 0.19701148569583893,
      "learning_rate": 4.3349184782608697e-05,
      "loss": 0.0396,
      "step": 980
    },
    {
      "epoch": 0.5380434782608695,
      "grad_norm": 0.5441235303878784,
      "learning_rate": 4.328125e-05,
      "loss": 0.0847,
      "step": 990
    },
    {
      "epoch": 0.5434782608695652,
      "grad_norm": 0.19661842286586761,
      "learning_rate": 4.321331521739131e-05,
      "loss": 0.0527,
      "step": 1000
    },
    {
      "epoch": 0.5489130434782609,
      "grad_norm": 0.18705394864082336,
      "learning_rate": 4.314538043478261e-05,
      "loss": 0.0502,
      "step": 1010
    },
    {
      "epoch": 0.5543478260869565,
      "grad_norm": 2.393697738647461,
      "learning_rate": 4.307744565217392e-05,
      "loss": 0.0465,
      "step": 1020
    },
    {
      "epoch": 0.5597826086956522,
      "grad_norm": 0.14701612293720245,
      "learning_rate": 4.300951086956522e-05,
      "loss": 0.0535,
      "step": 1030
    },
    {
      "epoch": 0.5652173913043478,
      "grad_norm": 1.4521607160568237,
      "learning_rate": 4.294157608695653e-05,
      "loss": 0.0562,
      "step": 1040
    },
    {
      "epoch": 0.5706521739130435,
      "grad_norm": 0.6496790051460266,
      "learning_rate": 4.287364130434783e-05,
      "loss": 0.0659,
      "step": 1050
    },
    {
      "epoch": 0.5760869565217391,
      "grad_norm": 0.1364382654428482,
      "learning_rate": 4.280570652173913e-05,
      "loss": 0.0894,
      "step": 1060
    },
    {
      "epoch": 0.5815217391304348,
      "grad_norm": 0.13824349641799927,
      "learning_rate": 4.273777173913044e-05,
      "loss": 0.0201,
      "step": 1070
    },
    {
      "epoch": 0.5869565217391305,
      "grad_norm": 0.13831405341625214,
      "learning_rate": 4.266983695652174e-05,
      "loss": 0.0285,
      "step": 1080
    },
    {
      "epoch": 0.592391304347826,
      "grad_norm": 0.12192331999540329,
      "learning_rate": 4.2601902173913044e-05,
      "loss": 0.051,
      "step": 1090
    },
    {
      "epoch": 0.5978260869565217,
      "grad_norm": 0.8327764272689819,
      "learning_rate": 4.253396739130435e-05,
      "loss": 0.0643,
      "step": 1100
    },
    {
      "epoch": 0.6032608695652174,
      "grad_norm": 3.0022261142730713,
      "learning_rate": 4.2466032608695654e-05,
      "loss": 0.0815,
      "step": 1110
    },
    {
      "epoch": 0.6086956521739131,
      "grad_norm": 0.18670864403247833,
      "learning_rate": 4.2398097826086956e-05,
      "loss": 0.0842,
      "step": 1120
    },
    {
      "epoch": 0.6141304347826086,
      "grad_norm": 0.09029851853847504,
      "learning_rate": 4.233016304347826e-05,
      "loss": 0.0443,
      "step": 1130
    },
    {
      "epoch": 0.6195652173913043,
      "grad_norm": 0.17856180667877197,
      "learning_rate": 4.2262228260869566e-05,
      "loss": 0.0296,
      "step": 1140
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.961069107055664,
      "learning_rate": 4.219429347826087e-05,
      "loss": 0.0674,
      "step": 1150
    },
    {
      "epoch": 0.6304347826086957,
      "grad_norm": 0.08797574788331985,
      "learning_rate": 4.2126358695652177e-05,
      "loss": 0.0369,
      "step": 1160
    },
    {
      "epoch": 0.6358695652173914,
      "grad_norm": 1.176522135734558,
      "learning_rate": 4.2058423913043485e-05,
      "loss": 0.0615,
      "step": 1170
    },
    {
      "epoch": 0.6413043478260869,
      "grad_norm": 1.4502938985824585,
      "learning_rate": 4.199048913043479e-05,
      "loss": 0.0648,
      "step": 1180
    },
    {
      "epoch": 0.6467391304347826,
      "grad_norm": 0.10207967460155487,
      "learning_rate": 4.192255434782609e-05,
      "loss": 0.0704,
      "step": 1190
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": 0.10258118808269501,
      "learning_rate": 4.18546195652174e-05,
      "loss": 0.0968,
      "step": 1200
    },
    {
      "epoch": 0.657608695652174,
      "grad_norm": 0.4592839181423187,
      "learning_rate": 4.17866847826087e-05,
      "loss": 0.048,
      "step": 1210
    },
    {
      "epoch": 0.6630434782608695,
      "grad_norm": 0.5948627591133118,
      "learning_rate": 4.171875e-05,
      "loss": 0.0584,
      "step": 1220
    },
    {
      "epoch": 0.6684782608695652,
      "grad_norm": 1.7459797859191895,
      "learning_rate": 4.165081521739131e-05,
      "loss": 0.0409,
      "step": 1230
    },
    {
      "epoch": 0.6739130434782609,
      "grad_norm": 0.13916204869747162,
      "learning_rate": 4.158288043478261e-05,
      "loss": 0.0304,
      "step": 1240
    },
    {
      "epoch": 0.6793478260869565,
      "grad_norm": 0.08892633020877838,
      "learning_rate": 4.151494565217391e-05,
      "loss": 0.0473,
      "step": 1250
    },
    {
      "epoch": 0.6847826086956522,
      "grad_norm": 0.13776417076587677,
      "learning_rate": 4.1447010869565215e-05,
      "loss": 0.0533,
      "step": 1260
    },
    {
      "epoch": 0.6902173913043478,
      "grad_norm": 2.4989330768585205,
      "learning_rate": 4.1379076086956524e-05,
      "loss": 0.0482,
      "step": 1270
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 0.9539056420326233,
      "learning_rate": 4.1311141304347825e-05,
      "loss": 0.0764,
      "step": 1280
    },
    {
      "epoch": 0.7010869565217391,
      "grad_norm": 0.08194361627101898,
      "learning_rate": 4.124320652173913e-05,
      "loss": 0.0347,
      "step": 1290
    },
    {
      "epoch": 0.7065217391304348,
      "grad_norm": 1.9745999574661255,
      "learning_rate": 4.1175271739130436e-05,
      "loss": 0.0563,
      "step": 1300
    },
    {
      "epoch": 0.7119565217391305,
      "grad_norm": 1.5261659622192383,
      "learning_rate": 4.1107336956521744e-05,
      "loss": 0.0588,
      "step": 1310
    },
    {
      "epoch": 0.717391304347826,
      "grad_norm": 0.07512395828962326,
      "learning_rate": 4.1039402173913046e-05,
      "loss": 0.0194,
      "step": 1320
    },
    {
      "epoch": 0.7228260869565217,
      "grad_norm": 0.05252643674612045,
      "learning_rate": 4.0971467391304355e-05,
      "loss": 0.0598,
      "step": 1330
    },
    {
      "epoch": 0.7282608695652174,
      "grad_norm": 0.12330728769302368,
      "learning_rate": 4.090353260869566e-05,
      "loss": 0.0386,
      "step": 1340
    },
    {
      "epoch": 0.7336956521739131,
      "grad_norm": 2.470388889312744,
      "learning_rate": 4.083559782608696e-05,
      "loss": 0.0652,
      "step": 1350
    },
    {
      "epoch": 0.7391304347826086,
      "grad_norm": 0.0683283880352974,
      "learning_rate": 4.076766304347826e-05,
      "loss": 0.0383,
      "step": 1360
    },
    {
      "epoch": 0.7445652173913043,
      "grad_norm": 1.5735622644424438,
      "learning_rate": 4.069972826086957e-05,
      "loss": 0.0342,
      "step": 1370
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.09759846329689026,
      "learning_rate": 4.063179347826087e-05,
      "loss": 0.0362,
      "step": 1380
    },
    {
      "epoch": 0.7554347826086957,
      "grad_norm": 2.202094554901123,
      "learning_rate": 4.056385869565217e-05,
      "loss": 0.0698,
      "step": 1390
    },
    {
      "epoch": 0.7608695652173914,
      "grad_norm": 0.0641360878944397,
      "learning_rate": 4.049592391304348e-05,
      "loss": 0.0431,
      "step": 1400
    },
    {
      "epoch": 0.7663043478260869,
      "grad_norm": 0.09597282856702805,
      "learning_rate": 4.042798913043478e-05,
      "loss": 0.0284,
      "step": 1410
    },
    {
      "epoch": 0.7717391304347826,
      "grad_norm": 0.11068975180387497,
      "learning_rate": 4.0360054347826085e-05,
      "loss": 0.0276,
      "step": 1420
    },
    {
      "epoch": 0.7771739130434783,
      "grad_norm": 1.8586657047271729,
      "learning_rate": 4.029211956521739e-05,
      "loss": 0.0823,
      "step": 1430
    },
    {
      "epoch": 0.782608695652174,
      "grad_norm": 0.07608076930046082,
      "learning_rate": 4.0224184782608695e-05,
      "loss": 0.0391,
      "step": 1440
    },
    {
      "epoch": 0.7880434782608695,
      "grad_norm": 0.08237726241350174,
      "learning_rate": 4.0156250000000004e-05,
      "loss": 0.011,
      "step": 1450
    },
    {
      "epoch": 0.7934782608695652,
      "grad_norm": 1.0406575202941895,
      "learning_rate": 4.008831521739131e-05,
      "loss": 0.0484,
      "step": 1460
    },
    {
      "epoch": 0.7989130434782609,
      "grad_norm": 0.848357081413269,
      "learning_rate": 4.0020380434782614e-05,
      "loss": 0.0299,
      "step": 1470
    },
    {
      "epoch": 0.8043478260869565,
      "grad_norm": 0.08370786905288696,
      "learning_rate": 3.9952445652173916e-05,
      "loss": 0.0223,
      "step": 1480
    },
    {
      "epoch": 0.8097826086956522,
      "grad_norm": 0.8768998980522156,
      "learning_rate": 3.988451086956522e-05,
      "loss": 0.0361,
      "step": 1490
    },
    {
      "epoch": 0.8152173913043478,
      "grad_norm": 0.8384037613868713,
      "learning_rate": 3.9816576086956526e-05,
      "loss": 0.0218,
      "step": 1500
    },
    {
      "epoch": 0.8206521739130435,
      "grad_norm": 2.473531723022461,
      "learning_rate": 3.974864130434783e-05,
      "loss": 0.0681,
      "step": 1510
    },
    {
      "epoch": 0.8260869565217391,
      "grad_norm": 0.31888481974601746,
      "learning_rate": 3.968070652173913e-05,
      "loss": 0.0084,
      "step": 1520
    },
    {
      "epoch": 0.8315217391304348,
      "grad_norm": 2.902362585067749,
      "learning_rate": 3.961277173913044e-05,
      "loss": 0.0596,
      "step": 1530
    },
    {
      "epoch": 0.8369565217391305,
      "grad_norm": 2.249988555908203,
      "learning_rate": 3.954483695652174e-05,
      "loss": 0.0431,
      "step": 1540
    },
    {
      "epoch": 0.842391304347826,
      "grad_norm": 0.04377551004290581,
      "learning_rate": 3.947690217391304e-05,
      "loss": 0.0841,
      "step": 1550
    },
    {
      "epoch": 0.8478260869565217,
      "grad_norm": 0.05939460173249245,
      "learning_rate": 3.940896739130435e-05,
      "loss": 0.0374,
      "step": 1560
    },
    {
      "epoch": 0.8532608695652174,
      "grad_norm": 2.1426165103912354,
      "learning_rate": 3.934103260869565e-05,
      "loss": 0.0544,
      "step": 1570
    },
    {
      "epoch": 0.8586956521739131,
      "grad_norm": 2.117908000946045,
      "learning_rate": 3.9273097826086954e-05,
      "loss": 0.0571,
      "step": 1580
    },
    {
      "epoch": 0.8641304347826086,
      "grad_norm": 0.3523964583873749,
      "learning_rate": 3.920516304347826e-05,
      "loss": 0.0307,
      "step": 1590
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 0.552574872970581,
      "learning_rate": 3.913722826086957e-05,
      "loss": 0.0765,
      "step": 1600
    },
    {
      "epoch": 0.875,
      "grad_norm": 2.071855306625366,
      "learning_rate": 3.906929347826087e-05,
      "loss": 0.0686,
      "step": 1610
    },
    {
      "epoch": 0.8804347826086957,
      "grad_norm": 1.9984811544418335,
      "learning_rate": 3.9001358695652175e-05,
      "loss": 0.0517,
      "step": 1620
    },
    {
      "epoch": 0.8858695652173914,
      "grad_norm": 0.03906955197453499,
      "learning_rate": 3.8933423913043484e-05,
      "loss": 0.0397,
      "step": 1630
    },
    {
      "epoch": 0.8913043478260869,
      "grad_norm": 2.584437847137451,
      "learning_rate": 3.8865489130434786e-05,
      "loss": 0.0432,
      "step": 1640
    },
    {
      "epoch": 0.8967391304347826,
      "grad_norm": 0.05213884264230728,
      "learning_rate": 3.879755434782609e-05,
      "loss": 0.0723,
      "step": 1650
    },
    {
      "epoch": 0.9021739130434783,
      "grad_norm": 1.8839408159255981,
      "learning_rate": 3.8729619565217396e-05,
      "loss": 0.0382,
      "step": 1660
    },
    {
      "epoch": 0.907608695652174,
      "grad_norm": 0.03953828662633896,
      "learning_rate": 3.86616847826087e-05,
      "loss": 0.0324,
      "step": 1670
    },
    {
      "epoch": 0.9130434782608695,
      "grad_norm": 2.1907691955566406,
      "learning_rate": 3.859375e-05,
      "loss": 0.059,
      "step": 1680
    },
    {
      "epoch": 0.9184782608695652,
      "grad_norm": 0.06585346162319183,
      "learning_rate": 3.852581521739131e-05,
      "loss": 0.0155,
      "step": 1690
    },
    {
      "epoch": 0.9239130434782609,
      "grad_norm": 0.08030029386281967,
      "learning_rate": 3.845788043478261e-05,
      "loss": 0.0219,
      "step": 1700
    },
    {
      "epoch": 0.9293478260869565,
      "grad_norm": 1.0862737894058228,
      "learning_rate": 3.838994565217391e-05,
      "loss": 0.0453,
      "step": 1710
    },
    {
      "epoch": 0.9347826086956522,
      "grad_norm": 0.7965489029884338,
      "learning_rate": 3.8322010869565214e-05,
      "loss": 0.0735,
      "step": 1720
    },
    {
      "epoch": 0.9402173913043478,
      "grad_norm": 0.07894174009561539,
      "learning_rate": 3.825407608695652e-05,
      "loss": 0.0467,
      "step": 1730
    },
    {
      "epoch": 0.9456521739130435,
      "grad_norm": 0.15772585570812225,
      "learning_rate": 3.818614130434783e-05,
      "loss": 0.0523,
      "step": 1740
    },
    {
      "epoch": 0.9510869565217391,
      "grad_norm": 0.056873369961977005,
      "learning_rate": 3.811820652173913e-05,
      "loss": 0.0582,
      "step": 1750
    },
    {
      "epoch": 0.9565217391304348,
      "grad_norm": 0.27130642533302307,
      "learning_rate": 3.805027173913044e-05,
      "loss": 0.0123,
      "step": 1760
    },
    {
      "epoch": 0.9619565217391305,
      "grad_norm": 2.2092978954315186,
      "learning_rate": 3.798233695652174e-05,
      "loss": 0.0523,
      "step": 1770
    },
    {
      "epoch": 0.967391304347826,
      "grad_norm": 0.05126551166176796,
      "learning_rate": 3.7914402173913045e-05,
      "loss": 0.0241,
      "step": 1780
    },
    {
      "epoch": 0.9728260869565217,
      "grad_norm": 2.973544120788574,
      "learning_rate": 3.7846467391304353e-05,
      "loss": 0.0921,
      "step": 1790
    },
    {
      "epoch": 0.9782608695652174,
      "grad_norm": 0.039374109357595444,
      "learning_rate": 3.7778532608695655e-05,
      "loss": 0.0295,
      "step": 1800
    },
    {
      "epoch": 0.9836956521739131,
      "grad_norm": 0.682473361492157,
      "learning_rate": 3.771059782608696e-05,
      "loss": 0.0345,
      "step": 1810
    },
    {
      "epoch": 0.9891304347826086,
      "grad_norm": 0.0632256492972374,
      "learning_rate": 3.764266304347826e-05,
      "loss": 0.049,
      "step": 1820
    },
    {
      "epoch": 0.9945652173913043,
      "grad_norm": 0.08501124382019043,
      "learning_rate": 3.757472826086957e-05,
      "loss": 0.0198,
      "step": 1830
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.306655406951904,
      "learning_rate": 3.750679347826087e-05,
      "loss": 0.0695,
      "step": 1840
    },
    {
      "epoch": 1.0054347826086956,
      "grad_norm": 2.385530710220337,
      "learning_rate": 3.743885869565217e-05,
      "loss": 0.0673,
      "step": 1850
    },
    {
      "epoch": 1.0108695652173914,
      "grad_norm": 0.4739251732826233,
      "learning_rate": 3.737092391304348e-05,
      "loss": 0.0295,
      "step": 1860
    },
    {
      "epoch": 1.016304347826087,
      "grad_norm": 0.054410241544246674,
      "learning_rate": 3.730298913043478e-05,
      "loss": 0.0297,
      "step": 1870
    },
    {
      "epoch": 1.0217391304347827,
      "grad_norm": 2.7451634407043457,
      "learning_rate": 3.723505434782609e-05,
      "loss": 0.0443,
      "step": 1880
    },
    {
      "epoch": 1.0271739130434783,
      "grad_norm": 0.053176674991846085,
      "learning_rate": 3.71671195652174e-05,
      "loss": 0.0367,
      "step": 1890
    },
    {
      "epoch": 1.0326086956521738,
      "grad_norm": 0.05463583767414093,
      "learning_rate": 3.70991847826087e-05,
      "loss": 0.0684,
      "step": 1900
    },
    {
      "epoch": 1.0380434782608696,
      "grad_norm": 2.579294443130493,
      "learning_rate": 3.703125e-05,
      "loss": 0.07,
      "step": 1910
    },
    {
      "epoch": 1.0434782608695652,
      "grad_norm": 1.6764291524887085,
      "learning_rate": 3.696331521739131e-05,
      "loss": 0.0698,
      "step": 1920
    },
    {
      "epoch": 1.048913043478261,
      "grad_norm": 1.410011887550354,
      "learning_rate": 3.689538043478261e-05,
      "loss": 0.0441,
      "step": 1930
    },
    {
      "epoch": 1.0543478260869565,
      "grad_norm": 0.6150604486465454,
      "learning_rate": 3.6827445652173914e-05,
      "loss": 0.0203,
      "step": 1940
    },
    {
      "epoch": 1.059782608695652,
      "grad_norm": 0.8632075190544128,
      "learning_rate": 3.6759510869565216e-05,
      "loss": 0.0311,
      "step": 1950
    },
    {
      "epoch": 1.065217391304348,
      "grad_norm": 2.145711660385132,
      "learning_rate": 3.6691576086956525e-05,
      "loss": 0.0609,
      "step": 1960
    },
    {
      "epoch": 1.0706521739130435,
      "grad_norm": 2.602079391479492,
      "learning_rate": 3.662364130434783e-05,
      "loss": 0.0629,
      "step": 1970
    },
    {
      "epoch": 1.0760869565217392,
      "grad_norm": 0.05045069009065628,
      "learning_rate": 3.655570652173913e-05,
      "loss": 0.0435,
      "step": 1980
    },
    {
      "epoch": 1.0815217391304348,
      "grad_norm": 1.575195550918579,
      "learning_rate": 3.648777173913044e-05,
      "loss": 0.0603,
      "step": 1990
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 0.038471922278404236,
      "learning_rate": 3.641983695652174e-05,
      "loss": 0.052,
      "step": 2000
    },
    {
      "epoch": 1.0923913043478262,
      "grad_norm": 0.02895982749760151,
      "learning_rate": 3.635190217391304e-05,
      "loss": 0.0505,
      "step": 2010
    },
    {
      "epoch": 1.0978260869565217,
      "grad_norm": 0.08216463774442673,
      "learning_rate": 3.628396739130435e-05,
      "loss": 0.0564,
      "step": 2020
    },
    {
      "epoch": 1.1032608695652173,
      "grad_norm": 1.939827799797058,
      "learning_rate": 3.621603260869566e-05,
      "loss": 0.025,
      "step": 2030
    },
    {
      "epoch": 1.108695652173913,
      "grad_norm": 0.06788834929466248,
      "learning_rate": 3.614809782608696e-05,
      "loss": 0.0506,
      "step": 2040
    },
    {
      "epoch": 1.1141304347826086,
      "grad_norm": 2.8375885486602783,
      "learning_rate": 3.608016304347826e-05,
      "loss": 0.048,
      "step": 2050
    },
    {
      "epoch": 1.1195652173913044,
      "grad_norm": 1.5293854475021362,
      "learning_rate": 3.601222826086957e-05,
      "loss": 0.0524,
      "step": 2060
    },
    {
      "epoch": 1.125,
      "grad_norm": 0.7208583354949951,
      "learning_rate": 3.594429347826087e-05,
      "loss": 0.0395,
      "step": 2070
    },
    {
      "epoch": 1.1304347826086956,
      "grad_norm": 0.057807959616184235,
      "learning_rate": 3.5876358695652174e-05,
      "loss": 0.0381,
      "step": 2080
    },
    {
      "epoch": 1.1358695652173914,
      "grad_norm": 0.997647762298584,
      "learning_rate": 3.580842391304348e-05,
      "loss": 0.0305,
      "step": 2090
    },
    {
      "epoch": 1.141304347826087,
      "grad_norm": 0.07180130481719971,
      "learning_rate": 3.5740489130434784e-05,
      "loss": 0.0263,
      "step": 2100
    },
    {
      "epoch": 1.1467391304347827,
      "grad_norm": 0.06021019071340561,
      "learning_rate": 3.5672554347826086e-05,
      "loss": 0.0048,
      "step": 2110
    },
    {
      "epoch": 1.1521739130434783,
      "grad_norm": 0.0540706031024456,
      "learning_rate": 3.5604619565217395e-05,
      "loss": 0.0694,
      "step": 2120
    },
    {
      "epoch": 1.1576086956521738,
      "grad_norm": 1.1711865663528442,
      "learning_rate": 3.5536684782608696e-05,
      "loss": 0.0674,
      "step": 2130
    },
    {
      "epoch": 1.1630434782608696,
      "grad_norm": 1.2531845569610596,
      "learning_rate": 3.546875e-05,
      "loss": 0.0157,
      "step": 2140
    },
    {
      "epoch": 1.1684782608695652,
      "grad_norm": 0.06216954067349434,
      "learning_rate": 3.540081521739131e-05,
      "loss": 0.0788,
      "step": 2150
    },
    {
      "epoch": 1.1739130434782608,
      "grad_norm": 2.4161250591278076,
      "learning_rate": 3.533288043478261e-05,
      "loss": 0.0624,
      "step": 2160
    },
    {
      "epoch": 1.1793478260869565,
      "grad_norm": 0.47166815400123596,
      "learning_rate": 3.526494565217392e-05,
      "loss": 0.0288,
      "step": 2170
    },
    {
      "epoch": 1.184782608695652,
      "grad_norm": 0.043044768273830414,
      "learning_rate": 3.519701086956522e-05,
      "loss": 0.0332,
      "step": 2180
    },
    {
      "epoch": 1.190217391304348,
      "grad_norm": 1.0184135437011719,
      "learning_rate": 3.512907608695653e-05,
      "loss": 0.0221,
      "step": 2190
    },
    {
      "epoch": 1.1956521739130435,
      "grad_norm": 0.4987489879131317,
      "learning_rate": 3.506114130434783e-05,
      "loss": 0.0469,
      "step": 2200
    },
    {
      "epoch": 1.2010869565217392,
      "grad_norm": 0.3952779769897461,
      "learning_rate": 3.499320652173913e-05,
      "loss": 0.0291,
      "step": 2210
    },
    {
      "epoch": 1.2065217391304348,
      "grad_norm": 2.271953821182251,
      "learning_rate": 3.492527173913044e-05,
      "loss": 0.0643,
      "step": 2220
    },
    {
      "epoch": 1.2119565217391304,
      "grad_norm": 0.03478975221514702,
      "learning_rate": 3.485733695652174e-05,
      "loss": 0.0289,
      "step": 2230
    },
    {
      "epoch": 1.2173913043478262,
      "grad_norm": 2.1330766677856445,
      "learning_rate": 3.4789402173913043e-05,
      "loss": 0.0457,
      "step": 2240
    },
    {
      "epoch": 1.2228260869565217,
      "grad_norm": 0.04078682139515877,
      "learning_rate": 3.472146739130435e-05,
      "loss": 0.0333,
      "step": 2250
    },
    {
      "epoch": 1.2282608695652173,
      "grad_norm": 0.030077490955591202,
      "learning_rate": 3.4653532608695654e-05,
      "loss": 0.0372,
      "step": 2260
    },
    {
      "epoch": 1.233695652173913,
      "grad_norm": 0.032515015453100204,
      "learning_rate": 3.4585597826086956e-05,
      "loss": 0.0307,
      "step": 2270
    },
    {
      "epoch": 1.2391304347826086,
      "grad_norm": 0.04072099179029465,
      "learning_rate": 3.451766304347826e-05,
      "loss": 0.0469,
      "step": 2280
    },
    {
      "epoch": 1.2445652173913044,
      "grad_norm": 0.03413150832056999,
      "learning_rate": 3.4449728260869566e-05,
      "loss": 0.0138,
      "step": 2290
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.5198123455047607,
      "learning_rate": 3.438179347826087e-05,
      "loss": 0.0983,
      "step": 2300
    },
    {
      "epoch": 1.2554347826086958,
      "grad_norm": 0.019824016839265823,
      "learning_rate": 3.4313858695652176e-05,
      "loss": 0.0257,
      "step": 2310
    },
    {
      "epoch": 1.2608695652173914,
      "grad_norm": 0.9589781761169434,
      "learning_rate": 3.4245923913043485e-05,
      "loss": 0.0093,
      "step": 2320
    },
    {
      "epoch": 1.266304347826087,
      "grad_norm": 0.15023869276046753,
      "learning_rate": 3.417798913043479e-05,
      "loss": 0.0713,
      "step": 2330
    },
    {
      "epoch": 1.2717391304347827,
      "grad_norm": 0.281875342130661,
      "learning_rate": 3.411005434782609e-05,
      "loss": 0.026,
      "step": 2340
    },
    {
      "epoch": 1.2771739130434783,
      "grad_norm": 0.05272279307246208,
      "learning_rate": 3.40421195652174e-05,
      "loss": 0.0374,
      "step": 2350
    },
    {
      "epoch": 1.2826086956521738,
      "grad_norm": 2.698089599609375,
      "learning_rate": 3.39741847826087e-05,
      "loss": 0.0434,
      "step": 2360
    },
    {
      "epoch": 1.2880434782608696,
      "grad_norm": 0.15134766697883606,
      "learning_rate": 3.390625e-05,
      "loss": 0.1047,
      "step": 2370
    },
    {
      "epoch": 1.2934782608695652,
      "grad_norm": 0.02708657830953598,
      "learning_rate": 3.383831521739131e-05,
      "loss": 0.028,
      "step": 2380
    },
    {
      "epoch": 1.2989130434782608,
      "grad_norm": 1.2950420379638672,
      "learning_rate": 3.377038043478261e-05,
      "loss": 0.0597,
      "step": 2390
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 0.036510858684778214,
      "learning_rate": 3.370244565217391e-05,
      "loss": 0.0392,
      "step": 2400
    },
    {
      "epoch": 1.309782608695652,
      "grad_norm": 0.029915673658251762,
      "learning_rate": 3.3634510869565215e-05,
      "loss": 0.0412,
      "step": 2410
    },
    {
      "epoch": 1.315217391304348,
      "grad_norm": 2.0439164638519287,
      "learning_rate": 3.3566576086956523e-05,
      "loss": 0.056,
      "step": 2420
    },
    {
      "epoch": 1.3206521739130435,
      "grad_norm": 0.04167523235082626,
      "learning_rate": 3.3498641304347825e-05,
      "loss": 0.0326,
      "step": 2430
    },
    {
      "epoch": 1.3260869565217392,
      "grad_norm": 0.4419548511505127,
      "learning_rate": 3.343070652173913e-05,
      "loss": 0.037,
      "step": 2440
    },
    {
      "epoch": 1.3315217391304348,
      "grad_norm": 0.04203960299491882,
      "learning_rate": 3.3362771739130436e-05,
      "loss": 0.048,
      "step": 2450
    },
    {
      "epoch": 1.3369565217391304,
      "grad_norm": 0.031199634075164795,
      "learning_rate": 3.3294836956521744e-05,
      "loss": 0.0147,
      "step": 2460
    },
    {
      "epoch": 1.3423913043478262,
      "grad_norm": 2.8583810329437256,
      "learning_rate": 3.3226902173913046e-05,
      "loss": 0.0764,
      "step": 2470
    },
    {
      "epoch": 1.3478260869565217,
      "grad_norm": 0.02819560281932354,
      "learning_rate": 3.3158967391304355e-05,
      "loss": 0.0563,
      "step": 2480
    },
    {
      "epoch": 1.3532608695652173,
      "grad_norm": 4.416644096374512,
      "learning_rate": 3.3091032608695656e-05,
      "loss": 0.0604,
      "step": 2490
    },
    {
      "epoch": 1.358695652173913,
      "grad_norm": 1.6872462034225464,
      "learning_rate": 3.302309782608696e-05,
      "loss": 0.0609,
      "step": 2500
    },
    {
      "epoch": 1.3641304347826086,
      "grad_norm": 0.04794096201658249,
      "learning_rate": 3.295516304347826e-05,
      "loss": 0.0509,
      "step": 2510
    },
    {
      "epoch": 1.3695652173913042,
      "grad_norm": 1.5943615436553955,
      "learning_rate": 3.288722826086957e-05,
      "loss": 0.043,
      "step": 2520
    },
    {
      "epoch": 1.375,
      "grad_norm": 1.8048242330551147,
      "learning_rate": 3.281929347826087e-05,
      "loss": 0.0437,
      "step": 2530
    },
    {
      "epoch": 1.3804347826086958,
      "grad_norm": 0.035492733120918274,
      "learning_rate": 3.275135869565217e-05,
      "loss": 0.0142,
      "step": 2540
    },
    {
      "epoch": 1.3858695652173914,
      "grad_norm": 0.615311861038208,
      "learning_rate": 3.268342391304348e-05,
      "loss": 0.0445,
      "step": 2550
    },
    {
      "epoch": 1.391304347826087,
      "grad_norm": 0.03392065688967705,
      "learning_rate": 3.261548913043478e-05,
      "loss": 0.0578,
      "step": 2560
    },
    {
      "epoch": 1.3967391304347827,
      "grad_norm": 0.3682020902633667,
      "learning_rate": 3.2547554347826085e-05,
      "loss": 0.0275,
      "step": 2570
    },
    {
      "epoch": 1.4021739130434783,
      "grad_norm": 0.05147918686270714,
      "learning_rate": 3.247961956521739e-05,
      "loss": 0.0196,
      "step": 2580
    },
    {
      "epoch": 1.4076086956521738,
      "grad_norm": 0.02463724836707115,
      "learning_rate": 3.2411684782608695e-05,
      "loss": 0.042,
      "step": 2590
    },
    {
      "epoch": 1.4130434782608696,
      "grad_norm": 0.024265091866254807,
      "learning_rate": 3.2343750000000004e-05,
      "loss": 0.0785,
      "step": 2600
    },
    {
      "epoch": 1.4184782608695652,
      "grad_norm": 1.3578073978424072,
      "learning_rate": 3.2275815217391305e-05,
      "loss": 0.0576,
      "step": 2610
    },
    {
      "epoch": 1.4239130434782608,
      "grad_norm": 0.036602966487407684,
      "learning_rate": 3.2207880434782614e-05,
      "loss": 0.0429,
      "step": 2620
    },
    {
      "epoch": 1.4293478260869565,
      "grad_norm": 0.030139204114675522,
      "learning_rate": 3.2139945652173916e-05,
      "loss": 0.0251,
      "step": 2630
    },
    {
      "epoch": 1.434782608695652,
      "grad_norm": 0.0283611249178648,
      "learning_rate": 3.207201086956522e-05,
      "loss": 0.0349,
      "step": 2640
    },
    {
      "epoch": 1.440217391304348,
      "grad_norm": 2.417900323867798,
      "learning_rate": 3.2004076086956526e-05,
      "loss": 0.0251,
      "step": 2650
    },
    {
      "epoch": 1.4456521739130435,
      "grad_norm": 0.2783670723438263,
      "learning_rate": 3.193614130434783e-05,
      "loss": 0.0253,
      "step": 2660
    },
    {
      "epoch": 1.4510869565217392,
      "grad_norm": 0.03953706845641136,
      "learning_rate": 3.186820652173913e-05,
      "loss": 0.0911,
      "step": 2670
    },
    {
      "epoch": 1.4565217391304348,
      "grad_norm": 0.02505555748939514,
      "learning_rate": 3.180027173913044e-05,
      "loss": 0.041,
      "step": 2680
    },
    {
      "epoch": 1.4619565217391304,
      "grad_norm": 0.02670893259346485,
      "learning_rate": 3.173233695652174e-05,
      "loss": 0.0869,
      "step": 2690
    },
    {
      "epoch": 1.4673913043478262,
      "grad_norm": 0.028627745807170868,
      "learning_rate": 3.166440217391304e-05,
      "loss": 0.0534,
      "step": 2700
    },
    {
      "epoch": 1.4728260869565217,
      "grad_norm": 0.02243303507566452,
      "learning_rate": 3.159646739130435e-05,
      "loss": 0.0165,
      "step": 2710
    },
    {
      "epoch": 1.4782608695652173,
      "grad_norm": 1.0297505855560303,
      "learning_rate": 3.152853260869565e-05,
      "loss": 0.0387,
      "step": 2720
    },
    {
      "epoch": 1.483695652173913,
      "grad_norm": 0.03779418393969536,
      "learning_rate": 3.1460597826086954e-05,
      "loss": 0.0347,
      "step": 2730
    },
    {
      "epoch": 1.4891304347826086,
      "grad_norm": 2.2722432613372803,
      "learning_rate": 3.139266304347826e-05,
      "loss": 0.0373,
      "step": 2740
    },
    {
      "epoch": 1.4945652173913042,
      "grad_norm": 0.03030433878302574,
      "learning_rate": 3.132472826086957e-05,
      "loss": 0.0586,
      "step": 2750
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7417194843292236,
      "learning_rate": 3.125679347826087e-05,
      "loss": 0.0639,
      "step": 2760
    },
    {
      "epoch": 1.5054347826086958,
      "grad_norm": 1.6412978172302246,
      "learning_rate": 3.1188858695652175e-05,
      "loss": 0.0316,
      "step": 2770
    },
    {
      "epoch": 1.5108695652173914,
      "grad_norm": 2.248246669769287,
      "learning_rate": 3.1120923913043484e-05,
      "loss": 0.0481,
      "step": 2780
    },
    {
      "epoch": 1.516304347826087,
      "grad_norm": 0.027135416865348816,
      "learning_rate": 3.1052989130434785e-05,
      "loss": 0.0384,
      "step": 2790
    },
    {
      "epoch": 1.5217391304347827,
      "grad_norm": 2.775738000869751,
      "learning_rate": 3.098505434782609e-05,
      "loss": 0.0595,
      "step": 2800
    },
    {
      "epoch": 1.5271739130434783,
      "grad_norm": 0.03302615135908127,
      "learning_rate": 3.0917119565217396e-05,
      "loss": 0.0278,
      "step": 2810
    },
    {
      "epoch": 1.5326086956521738,
      "grad_norm": 0.03724880889058113,
      "learning_rate": 3.08491847826087e-05,
      "loss": 0.0217,
      "step": 2820
    },
    {
      "epoch": 1.5380434782608696,
      "grad_norm": 2.214959144592285,
      "learning_rate": 3.078125e-05,
      "loss": 0.0329,
      "step": 2830
    },
    {
      "epoch": 1.5434782608695652,
      "grad_norm": 0.6907650828361511,
      "learning_rate": 3.071331521739131e-05,
      "loss": 0.0334,
      "step": 2840
    },
    {
      "epoch": 1.5489130434782608,
      "grad_norm": 2.032697916030884,
      "learning_rate": 3.064538043478261e-05,
      "loss": 0.0452,
      "step": 2850
    },
    {
      "epoch": 1.5543478260869565,
      "grad_norm": 2.454660415649414,
      "learning_rate": 3.057744565217391e-05,
      "loss": 0.0686,
      "step": 2860
    },
    {
      "epoch": 1.5597826086956523,
      "grad_norm": 0.2085021287202835,
      "learning_rate": 3.0509510869565217e-05,
      "loss": 0.0214,
      "step": 2870
    },
    {
      "epoch": 1.5652173913043477,
      "grad_norm": 0.9895591139793396,
      "learning_rate": 3.0441576086956525e-05,
      "loss": 0.0347,
      "step": 2880
    },
    {
      "epoch": 1.5706521739130435,
      "grad_norm": 0.02462504245340824,
      "learning_rate": 3.0373641304347827e-05,
      "loss": 0.0212,
      "step": 2890
    },
    {
      "epoch": 1.5760869565217392,
      "grad_norm": 2.076037883758545,
      "learning_rate": 3.030570652173913e-05,
      "loss": 0.0435,
      "step": 2900
    },
    {
      "epoch": 1.5815217391304348,
      "grad_norm": 0.5726887583732605,
      "learning_rate": 3.0237771739130438e-05,
      "loss": 0.0408,
      "step": 2910
    },
    {
      "epoch": 1.5869565217391304,
      "grad_norm": 1.521219253540039,
      "learning_rate": 3.016983695652174e-05,
      "loss": 0.0638,
      "step": 2920
    },
    {
      "epoch": 1.5923913043478262,
      "grad_norm": 1.550461769104004,
      "learning_rate": 3.0101902173913045e-05,
      "loss": 0.0767,
      "step": 2930
    },
    {
      "epoch": 1.5978260869565217,
      "grad_norm": 0.7388021945953369,
      "learning_rate": 3.0033967391304353e-05,
      "loss": 0.0248,
      "step": 2940
    },
    {
      "epoch": 1.6032608695652173,
      "grad_norm": 0.4668389558792114,
      "learning_rate": 2.9966032608695655e-05,
      "loss": 0.042,
      "step": 2950
    },
    {
      "epoch": 1.608695652173913,
      "grad_norm": 3.2297208309173584,
      "learning_rate": 2.9898097826086957e-05,
      "loss": 0.0349,
      "step": 2960
    },
    {
      "epoch": 1.6141304347826086,
      "grad_norm": 1.6428245306015015,
      "learning_rate": 2.983016304347826e-05,
      "loss": 0.0646,
      "step": 2970
    },
    {
      "epoch": 1.6195652173913042,
      "grad_norm": 0.9528246521949768,
      "learning_rate": 2.9762228260869567e-05,
      "loss": 0.0206,
      "step": 2980
    },
    {
      "epoch": 1.625,
      "grad_norm": 0.01599445566534996,
      "learning_rate": 2.969429347826087e-05,
      "loss": 0.0479,
      "step": 2990
    },
    {
      "epoch": 1.6304347826086958,
      "grad_norm": 2.1707496643066406,
      "learning_rate": 2.9626358695652174e-05,
      "loss": 0.0487,
      "step": 3000
    },
    {
      "epoch": 1.6358695652173914,
      "grad_norm": 0.02612907439470291,
      "learning_rate": 2.9558423913043483e-05,
      "loss": 0.0236,
      "step": 3010
    },
    {
      "epoch": 1.641304347826087,
      "grad_norm": 0.03574661165475845,
      "learning_rate": 2.9490489130434785e-05,
      "loss": 0.0193,
      "step": 3020
    },
    {
      "epoch": 1.6467391304347827,
      "grad_norm": 2.0244452953338623,
      "learning_rate": 2.9422554347826086e-05,
      "loss": 0.0305,
      "step": 3030
    },
    {
      "epoch": 1.6521739130434783,
      "grad_norm": 0.6404231786727905,
      "learning_rate": 2.9354619565217395e-05,
      "loss": 0.046,
      "step": 3040
    },
    {
      "epoch": 1.6576086956521738,
      "grad_norm": 0.23651741445064545,
      "learning_rate": 2.9286684782608697e-05,
      "loss": 0.039,
      "step": 3050
    },
    {
      "epoch": 1.6630434782608696,
      "grad_norm": 1.6075016260147095,
      "learning_rate": 2.921875e-05,
      "loss": 0.0365,
      "step": 3060
    },
    {
      "epoch": 1.6684782608695652,
      "grad_norm": 1.1421658992767334,
      "learning_rate": 2.9150815217391307e-05,
      "loss": 0.0572,
      "step": 3070
    },
    {
      "epoch": 1.6739130434782608,
      "grad_norm": 0.02493092603981495,
      "learning_rate": 2.9082880434782613e-05,
      "loss": 0.0472,
      "step": 3080
    },
    {
      "epoch": 1.6793478260869565,
      "grad_norm": 0.027605347335338593,
      "learning_rate": 2.9014945652173914e-05,
      "loss": 0.0274,
      "step": 3090
    },
    {
      "epoch": 1.6847826086956523,
      "grad_norm": 0.02174367383122444,
      "learning_rate": 2.8947010869565216e-05,
      "loss": 0.0304,
      "step": 3100
    },
    {
      "epoch": 1.6902173913043477,
      "grad_norm": 1.657539963722229,
      "learning_rate": 2.8879076086956525e-05,
      "loss": 0.0492,
      "step": 3110
    },
    {
      "epoch": 1.6956521739130435,
      "grad_norm": 0.5179305672645569,
      "learning_rate": 2.8811141304347827e-05,
      "loss": 0.0148,
      "step": 3120
    },
    {
      "epoch": 1.7010869565217392,
      "grad_norm": 0.9449882507324219,
      "learning_rate": 2.874320652173913e-05,
      "loss": 0.0653,
      "step": 3130
    },
    {
      "epoch": 1.7065217391304348,
      "grad_norm": 0.017461063340306282,
      "learning_rate": 2.8675271739130437e-05,
      "loss": 0.0708,
      "step": 3140
    },
    {
      "epoch": 1.7119565217391304,
      "grad_norm": 0.025773705914616585,
      "learning_rate": 2.8607336956521742e-05,
      "loss": 0.0215,
      "step": 3150
    },
    {
      "epoch": 1.7173913043478262,
      "grad_norm": 2.1664600372314453,
      "learning_rate": 2.8539402173913044e-05,
      "loss": 0.0363,
      "step": 3160
    },
    {
      "epoch": 1.7228260869565217,
      "grad_norm": 1.4283291101455688,
      "learning_rate": 2.8471467391304353e-05,
      "loss": 0.0616,
      "step": 3170
    },
    {
      "epoch": 1.7282608695652173,
      "grad_norm": 0.02587815374135971,
      "learning_rate": 2.8403532608695654e-05,
      "loss": 0.0505,
      "step": 3180
    },
    {
      "epoch": 1.733695652173913,
      "grad_norm": 2.602689027786255,
      "learning_rate": 2.8335597826086956e-05,
      "loss": 0.0718,
      "step": 3190
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 0.031682081520557404,
      "learning_rate": 2.826766304347826e-05,
      "loss": 0.0234,
      "step": 3200
    },
    {
      "epoch": 1.7445652173913042,
      "grad_norm": 0.02022651769220829,
      "learning_rate": 2.8199728260869567e-05,
      "loss": 0.0371,
      "step": 3210
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.2114555835723877,
      "learning_rate": 2.8131793478260872e-05,
      "loss": 0.0532,
      "step": 3220
    },
    {
      "epoch": 1.7554347826086958,
      "grad_norm": 0.9827485680580139,
      "learning_rate": 2.8063858695652174e-05,
      "loss": 0.0216,
      "step": 3230
    },
    {
      "epoch": 1.7608695652173914,
      "grad_norm": 0.021755028516054153,
      "learning_rate": 2.7995923913043482e-05,
      "loss": 0.0373,
      "step": 3240
    },
    {
      "epoch": 1.766304347826087,
      "grad_norm": 3.4565494060516357,
      "learning_rate": 2.7927989130434784e-05,
      "loss": 0.06,
      "step": 3250
    },
    {
      "epoch": 1.7717391304347827,
      "grad_norm": 2.6889467239379883,
      "learning_rate": 2.7860054347826086e-05,
      "loss": 0.0579,
      "step": 3260
    },
    {
      "epoch": 1.7771739130434783,
      "grad_norm": 0.023742124438285828,
      "learning_rate": 2.7792119565217394e-05,
      "loss": 0.0122,
      "step": 3270
    },
    {
      "epoch": 1.7826086956521738,
      "grad_norm": 0.016438735648989677,
      "learning_rate": 2.7724184782608696e-05,
      "loss": 0.0295,
      "step": 3280
    },
    {
      "epoch": 1.7880434782608696,
      "grad_norm": 2.3999733924865723,
      "learning_rate": 2.765625e-05,
      "loss": 0.0445,
      "step": 3290
    },
    {
      "epoch": 1.7934782608695652,
      "grad_norm": 0.02460765279829502,
      "learning_rate": 2.758831521739131e-05,
      "loss": 0.024,
      "step": 3300
    },
    {
      "epoch": 1.7989130434782608,
      "grad_norm": 0.5855584740638733,
      "learning_rate": 2.7520380434782612e-05,
      "loss": 0.0271,
      "step": 3310
    },
    {
      "epoch": 1.8043478260869565,
      "grad_norm": 0.019200220704078674,
      "learning_rate": 2.7452445652173914e-05,
      "loss": 0.0325,
      "step": 3320
    },
    {
      "epoch": 1.8097826086956523,
      "grad_norm": 0.021392328664660454,
      "learning_rate": 2.7384510869565215e-05,
      "loss": 0.0353,
      "step": 3330
    },
    {
      "epoch": 1.8152173913043477,
      "grad_norm": 1.927210807800293,
      "learning_rate": 2.7316576086956524e-05,
      "loss": 0.0155,
      "step": 3340
    },
    {
      "epoch": 1.8206521739130435,
      "grad_norm": 0.769557535648346,
      "learning_rate": 2.7248641304347826e-05,
      "loss": 0.0473,
      "step": 3350
    },
    {
      "epoch": 1.8260869565217392,
      "grad_norm": 0.017246423289179802,
      "learning_rate": 2.718070652173913e-05,
      "loss": 0.0324,
      "step": 3360
    },
    {
      "epoch": 1.8315217391304348,
      "grad_norm": 0.8575958013534546,
      "learning_rate": 2.711277173913044e-05,
      "loss": 0.0132,
      "step": 3370
    },
    {
      "epoch": 1.8369565217391304,
      "grad_norm": 3.0450618267059326,
      "learning_rate": 2.704483695652174e-05,
      "loss": 0.0488,
      "step": 3380
    },
    {
      "epoch": 1.8423913043478262,
      "grad_norm": 0.0096511822193861,
      "learning_rate": 2.6976902173913043e-05,
      "loss": 0.0249,
      "step": 3390
    },
    {
      "epoch": 1.8478260869565217,
      "grad_norm": 0.012639540247619152,
      "learning_rate": 2.6908967391304352e-05,
      "loss": 0.045,
      "step": 3400
    },
    {
      "epoch": 1.8532608695652173,
      "grad_norm": 0.02135884016752243,
      "learning_rate": 2.6841032608695654e-05,
      "loss": 0.0078,
      "step": 3410
    },
    {
      "epoch": 1.858695652173913,
      "grad_norm": 0.01612926460802555,
      "learning_rate": 2.6773097826086955e-05,
      "loss": 0.0149,
      "step": 3420
    },
    {
      "epoch": 1.8641304347826086,
      "grad_norm": 0.020700721070170403,
      "learning_rate": 2.670516304347826e-05,
      "loss": 0.0424,
      "step": 3430
    },
    {
      "epoch": 1.8695652173913042,
      "grad_norm": 0.025265691801905632,
      "learning_rate": 2.663722826086957e-05,
      "loss": 0.015,
      "step": 3440
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.022426683455705643,
      "learning_rate": 2.656929347826087e-05,
      "loss": 0.0382,
      "step": 3450
    },
    {
      "epoch": 1.8804347826086958,
      "grad_norm": 0.027156628668308258,
      "learning_rate": 2.6501358695652173e-05,
      "loss": 0.023,
      "step": 3460
    },
    {
      "epoch": 1.8858695652173914,
      "grad_norm": 0.035581473261117935,
      "learning_rate": 2.643342391304348e-05,
      "loss": 0.0635,
      "step": 3470
    },
    {
      "epoch": 1.891304347826087,
      "grad_norm": 0.02497882768511772,
      "learning_rate": 2.6365489130434783e-05,
      "loss": 0.0986,
      "step": 3480
    },
    {
      "epoch": 1.8967391304347827,
      "grad_norm": 7.76271390914917,
      "learning_rate": 2.6297554347826085e-05,
      "loss": 0.082,
      "step": 3490
    },
    {
      "epoch": 1.9021739130434783,
      "grad_norm": 0.02294882759451866,
      "learning_rate": 2.6229619565217394e-05,
      "loss": 0.0195,
      "step": 3500
    },
    {
      "epoch": 1.9076086956521738,
      "grad_norm": 2.574120044708252,
      "learning_rate": 2.61616847826087e-05,
      "loss": 0.0447,
      "step": 3510
    },
    {
      "epoch": 1.9130434782608696,
      "grad_norm": 2.0275869369506836,
      "learning_rate": 2.609375e-05,
      "loss": 0.0171,
      "step": 3520
    },
    {
      "epoch": 1.9184782608695652,
      "grad_norm": 1.9334639310836792,
      "learning_rate": 2.602581521739131e-05,
      "loss": 0.0295,
      "step": 3530
    },
    {
      "epoch": 1.9239130434782608,
      "grad_norm": 2.80365252494812,
      "learning_rate": 2.595788043478261e-05,
      "loss": 0.0675,
      "step": 3540
    },
    {
      "epoch": 1.9293478260869565,
      "grad_norm": 1.02201247215271,
      "learning_rate": 2.5889945652173913e-05,
      "loss": 0.0637,
      "step": 3550
    },
    {
      "epoch": 1.9347826086956523,
      "grad_norm": 1.1704167127609253,
      "learning_rate": 2.5822010869565215e-05,
      "loss": 0.0439,
      "step": 3560
    },
    {
      "epoch": 1.9402173913043477,
      "grad_norm": 1.0523271560668945,
      "learning_rate": 2.5754076086956523e-05,
      "loss": 0.044,
      "step": 3570
    },
    {
      "epoch": 1.9456521739130435,
      "grad_norm": 0.012951262295246124,
      "learning_rate": 2.568614130434783e-05,
      "loss": 0.0415,
      "step": 3580
    },
    {
      "epoch": 1.9510869565217392,
      "grad_norm": 0.016090692952275276,
      "learning_rate": 2.561820652173913e-05,
      "loss": 0.0023,
      "step": 3590
    },
    {
      "epoch": 1.9565217391304348,
      "grad_norm": 0.026499424129724503,
      "learning_rate": 2.555027173913044e-05,
      "loss": 0.0647,
      "step": 3600
    },
    {
      "epoch": 1.9619565217391304,
      "grad_norm": 0.8359277844429016,
      "learning_rate": 2.548233695652174e-05,
      "loss": 0.0266,
      "step": 3610
    },
    {
      "epoch": 1.9673913043478262,
      "grad_norm": 0.0189577117562294,
      "learning_rate": 2.5414402173913043e-05,
      "loss": 0.0313,
      "step": 3620
    },
    {
      "epoch": 1.9728260869565217,
      "grad_norm": 0.05274955928325653,
      "learning_rate": 2.534646739130435e-05,
      "loss": 0.0178,
      "step": 3630
    },
    {
      "epoch": 1.9782608695652173,
      "grad_norm": 1.1785061359405518,
      "learning_rate": 2.5278532608695653e-05,
      "loss": 0.0459,
      "step": 3640
    },
    {
      "epoch": 1.983695652173913,
      "grad_norm": 0.6032376885414124,
      "learning_rate": 2.5210597826086958e-05,
      "loss": 0.0321,
      "step": 3650
    },
    {
      "epoch": 1.9891304347826086,
      "grad_norm": 0.6908299326896667,
      "learning_rate": 2.514266304347826e-05,
      "loss": 0.0302,
      "step": 3660
    },
    {
      "epoch": 1.9945652173913042,
      "grad_norm": 0.028849437832832336,
      "learning_rate": 2.507472826086957e-05,
      "loss": 0.0237,
      "step": 3670
    },
    {
      "epoch": 2.0,
      "grad_norm": 4.924069881439209,
      "learning_rate": 2.500679347826087e-05,
      "loss": 0.0571,
      "step": 3680
    },
    {
      "epoch": 2.005434782608696,
      "grad_norm": 0.019320674240589142,
      "learning_rate": 2.4938858695652176e-05,
      "loss": 0.0174,
      "step": 3690
    },
    {
      "epoch": 2.010869565217391,
      "grad_norm": 0.017366547137498856,
      "learning_rate": 2.4870923913043477e-05,
      "loss": 0.0521,
      "step": 3700
    },
    {
      "epoch": 2.016304347826087,
      "grad_norm": 1.0613864660263062,
      "learning_rate": 2.4802989130434783e-05,
      "loss": 0.0368,
      "step": 3710
    },
    {
      "epoch": 2.0217391304347827,
      "grad_norm": 1.9432578086853027,
      "learning_rate": 2.4735054347826088e-05,
      "loss": 0.0289,
      "step": 3720
    },
    {
      "epoch": 2.027173913043478,
      "grad_norm": 0.02151583321392536,
      "learning_rate": 2.4667119565217393e-05,
      "loss": 0.0382,
      "step": 3730
    },
    {
      "epoch": 2.032608695652174,
      "grad_norm": 3.3564703464508057,
      "learning_rate": 2.4599184782608698e-05,
      "loss": 0.0455,
      "step": 3740
    },
    {
      "epoch": 2.0380434782608696,
      "grad_norm": 2.044196128845215,
      "learning_rate": 2.453125e-05,
      "loss": 0.0312,
      "step": 3750
    },
    {
      "epoch": 2.0434782608695654,
      "grad_norm": 0.5067154765129089,
      "learning_rate": 2.4463315217391305e-05,
      "loss": 0.0025,
      "step": 3760
    },
    {
      "epoch": 2.0489130434782608,
      "grad_norm": 1.5735127925872803,
      "learning_rate": 2.439538043478261e-05,
      "loss": 0.0322,
      "step": 3770
    },
    {
      "epoch": 2.0543478260869565,
      "grad_norm": 0.019823452457785606,
      "learning_rate": 2.4327445652173912e-05,
      "loss": 0.0253,
      "step": 3780
    },
    {
      "epoch": 2.0597826086956523,
      "grad_norm": 0.6242560148239136,
      "learning_rate": 2.4259510869565217e-05,
      "loss": 0.0028,
      "step": 3790
    },
    {
      "epoch": 2.0652173913043477,
      "grad_norm": 2.8880116939544678,
      "learning_rate": 2.4191576086956523e-05,
      "loss": 0.0253,
      "step": 3800
    },
    {
      "epoch": 2.0706521739130435,
      "grad_norm": 0.017768697813153267,
      "learning_rate": 2.4123641304347828e-05,
      "loss": 0.0252,
      "step": 3810
    },
    {
      "epoch": 2.0760869565217392,
      "grad_norm": 0.020713839679956436,
      "learning_rate": 2.4055706521739133e-05,
      "loss": 0.058,
      "step": 3820
    },
    {
      "epoch": 2.0815217391304346,
      "grad_norm": 1.4240968227386475,
      "learning_rate": 2.3987771739130435e-05,
      "loss": 0.0714,
      "step": 3830
    },
    {
      "epoch": 2.0869565217391304,
      "grad_norm": 0.21199658513069153,
      "learning_rate": 2.391983695652174e-05,
      "loss": 0.0657,
      "step": 3840
    },
    {
      "epoch": 2.092391304347826,
      "grad_norm": 0.3564211130142212,
      "learning_rate": 2.3851902173913042e-05,
      "loss": 0.0289,
      "step": 3850
    },
    {
      "epoch": 2.097826086956522,
      "grad_norm": 1.9426608085632324,
      "learning_rate": 2.3783967391304347e-05,
      "loss": 0.0815,
      "step": 3860
    },
    {
      "epoch": 2.1032608695652173,
      "grad_norm": 1.4338619709014893,
      "learning_rate": 2.3716032608695656e-05,
      "loss": 0.0362,
      "step": 3870
    },
    {
      "epoch": 2.108695652173913,
      "grad_norm": 2.7761073112487793,
      "learning_rate": 2.3648097826086957e-05,
      "loss": 0.064,
      "step": 3880
    },
    {
      "epoch": 2.114130434782609,
      "grad_norm": 2.1583993434906006,
      "learning_rate": 2.3580163043478263e-05,
      "loss": 0.0199,
      "step": 3890
    },
    {
      "epoch": 2.119565217391304,
      "grad_norm": 1.0442501306533813,
      "learning_rate": 2.3512228260869568e-05,
      "loss": 0.0456,
      "step": 3900
    },
    {
      "epoch": 2.125,
      "grad_norm": 1.8891732692718506,
      "learning_rate": 2.344429347826087e-05,
      "loss": 0.0328,
      "step": 3910
    },
    {
      "epoch": 2.130434782608696,
      "grad_norm": 1.7695180177688599,
      "learning_rate": 2.3376358695652175e-05,
      "loss": 0.0389,
      "step": 3920
    },
    {
      "epoch": 2.135869565217391,
      "grad_norm": 3.6719002723693848,
      "learning_rate": 2.330842391304348e-05,
      "loss": 0.0716,
      "step": 3930
    },
    {
      "epoch": 2.141304347826087,
      "grad_norm": 1.4869296550750732,
      "learning_rate": 2.3240489130434785e-05,
      "loss": 0.0383,
      "step": 3940
    },
    {
      "epoch": 2.1467391304347827,
      "grad_norm": 1.8258780241012573,
      "learning_rate": 2.317255434782609e-05,
      "loss": 0.0587,
      "step": 3950
    },
    {
      "epoch": 2.1521739130434785,
      "grad_norm": 0.019429631531238556,
      "learning_rate": 2.3104619565217392e-05,
      "loss": 0.0098,
      "step": 3960
    },
    {
      "epoch": 2.157608695652174,
      "grad_norm": 0.9569172859191895,
      "learning_rate": 2.3036684782608697e-05,
      "loss": 0.0271,
      "step": 3970
    },
    {
      "epoch": 2.1630434782608696,
      "grad_norm": 0.016552964225411415,
      "learning_rate": 2.296875e-05,
      "loss": 0.0327,
      "step": 3980
    },
    {
      "epoch": 2.1684782608695654,
      "grad_norm": 0.018229136243462563,
      "learning_rate": 2.2900815217391304e-05,
      "loss": 0.0543,
      "step": 3990
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.01012122817337513,
      "learning_rate": 2.283288043478261e-05,
      "loss": 0.0201,
      "step": 4000
    },
    {
      "epoch": 2.1793478260869565,
      "grad_norm": 1.7952966690063477,
      "learning_rate": 2.2764945652173915e-05,
      "loss": 0.063,
      "step": 4010
    },
    {
      "epoch": 2.1847826086956523,
      "grad_norm": 1.823684573173523,
      "learning_rate": 2.269701086956522e-05,
      "loss": 0.0333,
      "step": 4020
    },
    {
      "epoch": 2.1902173913043477,
      "grad_norm": 1.583439826965332,
      "learning_rate": 2.2629076086956522e-05,
      "loss": 0.045,
      "step": 4030
    },
    {
      "epoch": 2.1956521739130435,
      "grad_norm": 0.018639719113707542,
      "learning_rate": 2.2561141304347827e-05,
      "loss": 0.0775,
      "step": 4040
    },
    {
      "epoch": 2.2010869565217392,
      "grad_norm": 2.6727874279022217,
      "learning_rate": 2.2493206521739132e-05,
      "loss": 0.0459,
      "step": 4050
    },
    {
      "epoch": 2.2065217391304346,
      "grad_norm": 1.3030669689178467,
      "learning_rate": 2.2425271739130434e-05,
      "loss": 0.0403,
      "step": 4060
    },
    {
      "epoch": 2.2119565217391304,
      "grad_norm": 1.8508713245391846,
      "learning_rate": 2.235733695652174e-05,
      "loss": 0.0142,
      "step": 4070
    },
    {
      "epoch": 2.217391304347826,
      "grad_norm": 1.829928994178772,
      "learning_rate": 2.2289402173913044e-05,
      "loss": 0.0547,
      "step": 4080
    },
    {
      "epoch": 2.2228260869565215,
      "grad_norm": 0.9172459244728088,
      "learning_rate": 2.222146739130435e-05,
      "loss": 0.0268,
      "step": 4090
    },
    {
      "epoch": 2.2282608695652173,
      "grad_norm": 2.018392562866211,
      "learning_rate": 2.2153532608695655e-05,
      "loss": 0.0409,
      "step": 4100
    },
    {
      "epoch": 2.233695652173913,
      "grad_norm": 0.8206737637519836,
      "learning_rate": 2.2085597826086957e-05,
      "loss": 0.0467,
      "step": 4110
    },
    {
      "epoch": 2.239130434782609,
      "grad_norm": 1.483919382095337,
      "learning_rate": 2.2017663043478262e-05,
      "loss": 0.0316,
      "step": 4120
    },
    {
      "epoch": 2.244565217391304,
      "grad_norm": 0.016777174547314644,
      "learning_rate": 2.1949728260869567e-05,
      "loss": 0.0151,
      "step": 4130
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.014928559772670269,
      "learning_rate": 2.188179347826087e-05,
      "loss": 0.01,
      "step": 4140
    },
    {
      "epoch": 2.255434782608696,
      "grad_norm": 0.8807331919670105,
      "learning_rate": 2.1813858695652174e-05,
      "loss": 0.0543,
      "step": 4150
    },
    {
      "epoch": 2.260869565217391,
      "grad_norm": 0.020061135292053223,
      "learning_rate": 2.174592391304348e-05,
      "loss": 0.032,
      "step": 4160
    },
    {
      "epoch": 2.266304347826087,
      "grad_norm": 0.024560030549764633,
      "learning_rate": 2.1677989130434785e-05,
      "loss": 0.0654,
      "step": 4170
    },
    {
      "epoch": 2.2717391304347827,
      "grad_norm": 1.417263388633728,
      "learning_rate": 2.161005434782609e-05,
      "loss": 0.0322,
      "step": 4180
    },
    {
      "epoch": 2.2771739130434785,
      "grad_norm": 2.904083490371704,
      "learning_rate": 2.154211956521739e-05,
      "loss": 0.0338,
      "step": 4190
    },
    {
      "epoch": 2.282608695652174,
      "grad_norm": 0.022675801068544388,
      "learning_rate": 2.1474184782608697e-05,
      "loss": 0.0443,
      "step": 4200
    },
    {
      "epoch": 2.2880434782608696,
      "grad_norm": 2.340677261352539,
      "learning_rate": 2.140625e-05,
      "loss": 0.0367,
      "step": 4210
    },
    {
      "epoch": 2.2934782608695654,
      "grad_norm": 3.1132185459136963,
      "learning_rate": 2.1338315217391304e-05,
      "loss": 0.0713,
      "step": 4220
    },
    {
      "epoch": 2.2989130434782608,
      "grad_norm": 0.024636849761009216,
      "learning_rate": 2.1270380434782612e-05,
      "loss": 0.0294,
      "step": 4230
    },
    {
      "epoch": 2.3043478260869565,
      "grad_norm": 0.012928727082908154,
      "learning_rate": 2.1202445652173914e-05,
      "loss": 0.0666,
      "step": 4240
    },
    {
      "epoch": 2.3097826086956523,
      "grad_norm": 0.013107659295201302,
      "learning_rate": 2.113451086956522e-05,
      "loss": 0.0748,
      "step": 4250
    },
    {
      "epoch": 2.3152173913043477,
      "grad_norm": 0.6297359466552734,
      "learning_rate": 2.106657608695652e-05,
      "loss": 0.0284,
      "step": 4260
    },
    {
      "epoch": 2.3206521739130435,
      "grad_norm": 0.012350023724138737,
      "learning_rate": 2.0998641304347826e-05,
      "loss": 0.0175,
      "step": 4270
    },
    {
      "epoch": 2.3260869565217392,
      "grad_norm": 0.2465524971485138,
      "learning_rate": 2.093070652173913e-05,
      "loss": 0.0195,
      "step": 4280
    },
    {
      "epoch": 2.3315217391304346,
      "grad_norm": 0.014330442994832993,
      "learning_rate": 2.0862771739130433e-05,
      "loss": 0.0372,
      "step": 4290
    },
    {
      "epoch": 2.3369565217391304,
      "grad_norm": 2.4345314502716064,
      "learning_rate": 2.0794836956521742e-05,
      "loss": 0.0388,
      "step": 4300
    },
    {
      "epoch": 2.342391304347826,
      "grad_norm": 1.8124513626098633,
      "learning_rate": 2.0726902173913044e-05,
      "loss": 0.0424,
      "step": 4310
    },
    {
      "epoch": 2.3478260869565215,
      "grad_norm": 1.1241285800933838,
      "learning_rate": 2.065896739130435e-05,
      "loss": 0.051,
      "step": 4320
    },
    {
      "epoch": 2.3532608695652173,
      "grad_norm": 0.01991748809814453,
      "learning_rate": 2.0591032608695654e-05,
      "loss": 0.0161,
      "step": 4330
    },
    {
      "epoch": 2.358695652173913,
      "grad_norm": 0.6510301828384399,
      "learning_rate": 2.0523097826086956e-05,
      "loss": 0.0571,
      "step": 4340
    },
    {
      "epoch": 2.364130434782609,
      "grad_norm": 0.7639111280441284,
      "learning_rate": 2.045516304347826e-05,
      "loss": 0.0509,
      "step": 4350
    },
    {
      "epoch": 2.369565217391304,
      "grad_norm": 1.9609839916229248,
      "learning_rate": 2.0387228260869566e-05,
      "loss": 0.0222,
      "step": 4360
    },
    {
      "epoch": 2.375,
      "grad_norm": 0.013139443472027779,
      "learning_rate": 2.031929347826087e-05,
      "loss": 0.0637,
      "step": 4370
    },
    {
      "epoch": 2.380434782608696,
      "grad_norm": 0.6709627509117126,
      "learning_rate": 2.0251358695652177e-05,
      "loss": 0.019,
      "step": 4380
    },
    {
      "epoch": 2.385869565217391,
      "grad_norm": 0.028568539768457413,
      "learning_rate": 2.018342391304348e-05,
      "loss": 0.0337,
      "step": 4390
    },
    {
      "epoch": 2.391304347826087,
      "grad_norm": 0.014949307776987553,
      "learning_rate": 2.0115489130434784e-05,
      "loss": 0.0397,
      "step": 4400
    },
    {
      "epoch": 2.3967391304347827,
      "grad_norm": 0.014501525089144707,
      "learning_rate": 2.004755434782609e-05,
      "loss": 0.0404,
      "step": 4410
    },
    {
      "epoch": 2.4021739130434785,
      "grad_norm": 1.9376801252365112,
      "learning_rate": 1.997961956521739e-05,
      "loss": 0.038,
      "step": 4420
    },
    {
      "epoch": 2.407608695652174,
      "grad_norm": 0.022872939705848694,
      "learning_rate": 1.9911684782608696e-05,
      "loss": 0.0076,
      "step": 4430
    },
    {
      "epoch": 2.4130434782608696,
      "grad_norm": 0.011418003588914871,
      "learning_rate": 1.984375e-05,
      "loss": 0.0438,
      "step": 4440
    },
    {
      "epoch": 2.4184782608695654,
      "grad_norm": 2.4273178577423096,
      "learning_rate": 1.9775815217391306e-05,
      "loss": 0.024,
      "step": 4450
    },
    {
      "epoch": 2.4239130434782608,
      "grad_norm": 3.5193309783935547,
      "learning_rate": 1.970788043478261e-05,
      "loss": 0.0352,
      "step": 4460
    },
    {
      "epoch": 2.4293478260869565,
      "grad_norm": 0.011528066359460354,
      "learning_rate": 1.9639945652173913e-05,
      "loss": 0.01,
      "step": 4470
    },
    {
      "epoch": 2.4347826086956523,
      "grad_norm": 1.7203865051269531,
      "learning_rate": 1.957201086956522e-05,
      "loss": 0.0406,
      "step": 4480
    },
    {
      "epoch": 2.4402173913043477,
      "grad_norm": 1.658400535583496,
      "learning_rate": 1.950407608695652e-05,
      "loss": 0.0394,
      "step": 4490
    },
    {
      "epoch": 2.4456521739130435,
      "grad_norm": 1.8929123878479004,
      "learning_rate": 1.9436141304347826e-05,
      "loss": 0.0564,
      "step": 4500
    },
    {
      "epoch": 2.4510869565217392,
      "grad_norm": 1.5054115056991577,
      "learning_rate": 1.936820652173913e-05,
      "loss": 0.0241,
      "step": 4510
    },
    {
      "epoch": 2.4565217391304346,
      "grad_norm": 0.011965624988079071,
      "learning_rate": 1.9300271739130436e-05,
      "loss": 0.0392,
      "step": 4520
    },
    {
      "epoch": 2.4619565217391304,
      "grad_norm": 0.011174014769494534,
      "learning_rate": 1.923233695652174e-05,
      "loss": 0.0123,
      "step": 4530
    },
    {
      "epoch": 2.467391304347826,
      "grad_norm": 0.00952005572617054,
      "learning_rate": 1.9164402173913043e-05,
      "loss": 0.0353,
      "step": 4540
    },
    {
      "epoch": 2.4728260869565215,
      "grad_norm": 2.4148545265197754,
      "learning_rate": 1.9096467391304348e-05,
      "loss": 0.0768,
      "step": 4550
    },
    {
      "epoch": 2.4782608695652173,
      "grad_norm": 0.5479761362075806,
      "learning_rate": 1.9028532608695653e-05,
      "loss": 0.0243,
      "step": 4560
    },
    {
      "epoch": 2.483695652173913,
      "grad_norm": 0.010212316177785397,
      "learning_rate": 1.8960597826086955e-05,
      "loss": 0.0099,
      "step": 4570
    },
    {
      "epoch": 2.489130434782609,
      "grad_norm": 0.01120524201542139,
      "learning_rate": 1.889266304347826e-05,
      "loss": 0.0517,
      "step": 4580
    },
    {
      "epoch": 2.494565217391304,
      "grad_norm": 0.01939789578318596,
      "learning_rate": 1.882472826086957e-05,
      "loss": 0.0403,
      "step": 4590
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.338428497314453,
      "learning_rate": 1.875679347826087e-05,
      "loss": 0.0417,
      "step": 4600
    },
    {
      "epoch": 2.505434782608696,
      "grad_norm": 0.0122992480173707,
      "learning_rate": 1.8688858695652176e-05,
      "loss": 0.0704,
      "step": 4610
    },
    {
      "epoch": 2.5108695652173916,
      "grad_norm": 3.09572172164917,
      "learning_rate": 1.8620923913043478e-05,
      "loss": 0.0379,
      "step": 4620
    },
    {
      "epoch": 2.516304347826087,
      "grad_norm": 0.013576941564679146,
      "learning_rate": 1.8552989130434783e-05,
      "loss": 0.0302,
      "step": 4630
    },
    {
      "epoch": 2.5217391304347827,
      "grad_norm": 0.007749562617391348,
      "learning_rate": 1.8485054347826088e-05,
      "loss": 0.0354,
      "step": 4640
    },
    {
      "epoch": 2.5271739130434785,
      "grad_norm": 1.3721004724502563,
      "learning_rate": 1.841711956521739e-05,
      "loss": 0.0576,
      "step": 4650
    },
    {
      "epoch": 2.532608695652174,
      "grad_norm": 1.0776575803756714,
      "learning_rate": 1.83491847826087e-05,
      "loss": 0.024,
      "step": 4660
    },
    {
      "epoch": 2.5380434782608696,
      "grad_norm": 0.011249735951423645,
      "learning_rate": 1.828125e-05,
      "loss": 0.0326,
      "step": 4670
    },
    {
      "epoch": 2.5434782608695654,
      "grad_norm": 2.629910707473755,
      "learning_rate": 1.8213315217391306e-05,
      "loss": 0.05,
      "step": 4680
    },
    {
      "epoch": 2.5489130434782608,
      "grad_norm": 0.014282306656241417,
      "learning_rate": 1.814538043478261e-05,
      "loss": 0.0397,
      "step": 4690
    },
    {
      "epoch": 2.5543478260869565,
      "grad_norm": 0.0061948285438120365,
      "learning_rate": 1.8077445652173913e-05,
      "loss": 0.0912,
      "step": 4700
    },
    {
      "epoch": 2.5597826086956523,
      "grad_norm": 0.014433154836297035,
      "learning_rate": 1.8009510869565218e-05,
      "loss": 0.0081,
      "step": 4710
    },
    {
      "epoch": 2.5652173913043477,
      "grad_norm": 0.00747031020000577,
      "learning_rate": 1.794157608695652e-05,
      "loss": 0.0404,
      "step": 4720
    },
    {
      "epoch": 2.5706521739130435,
      "grad_norm": 0.01279089692980051,
      "learning_rate": 1.787364130434783e-05,
      "loss": 0.0293,
      "step": 4730
    },
    {
      "epoch": 2.5760869565217392,
      "grad_norm": 1.28276526927948,
      "learning_rate": 1.7805706521739134e-05,
      "loss": 0.023,
      "step": 4740
    },
    {
      "epoch": 2.5815217391304346,
      "grad_norm": 0.010591172613203526,
      "learning_rate": 1.7737771739130435e-05,
      "loss": 0.0581,
      "step": 4750
    },
    {
      "epoch": 2.5869565217391304,
      "grad_norm": 0.01254231110215187,
      "learning_rate": 1.766983695652174e-05,
      "loss": 0.0199,
      "step": 4760
    },
    {
      "epoch": 2.592391304347826,
      "grad_norm": 0.013557860627770424,
      "learning_rate": 1.7601902173913042e-05,
      "loss": 0.0238,
      "step": 4770
    },
    {
      "epoch": 2.5978260869565215,
      "grad_norm": 1.832394003868103,
      "learning_rate": 1.7533967391304348e-05,
      "loss": 0.0181,
      "step": 4780
    },
    {
      "epoch": 2.6032608695652173,
      "grad_norm": 0.9708284139633179,
      "learning_rate": 1.7466032608695653e-05,
      "loss": 0.0166,
      "step": 4790
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 0.4326236844062805,
      "learning_rate": 1.7398097826086958e-05,
      "loss": 0.014,
      "step": 4800
    },
    {
      "epoch": 2.6141304347826084,
      "grad_norm": 0.4434240460395813,
      "learning_rate": 1.7330163043478263e-05,
      "loss": 0.0268,
      "step": 4810
    },
    {
      "epoch": 2.619565217391304,
      "grad_norm": 2.1351823806762695,
      "learning_rate": 1.726222826086957e-05,
      "loss": 0.018,
      "step": 4820
    },
    {
      "epoch": 2.625,
      "grad_norm": 1.0880440473556519,
      "learning_rate": 1.719429347826087e-05,
      "loss": 0.0295,
      "step": 4830
    },
    {
      "epoch": 2.630434782608696,
      "grad_norm": 0.3998560905456543,
      "learning_rate": 1.7126358695652175e-05,
      "loss": 0.0182,
      "step": 4840
    },
    {
      "epoch": 2.6358695652173916,
      "grad_norm": 0.39815548062324524,
      "learning_rate": 1.7058423913043477e-05,
      "loss": 0.0364,
      "step": 4850
    },
    {
      "epoch": 2.641304347826087,
      "grad_norm": 2.2759053707122803,
      "learning_rate": 1.6990489130434782e-05,
      "loss": 0.105,
      "step": 4860
    },
    {
      "epoch": 2.6467391304347827,
      "grad_norm": 0.018731435760855675,
      "learning_rate": 1.6922554347826088e-05,
      "loss": 0.0319,
      "step": 4870
    },
    {
      "epoch": 2.6521739130434785,
      "grad_norm": 0.0077615417540073395,
      "learning_rate": 1.6854619565217393e-05,
      "loss": 0.0134,
      "step": 4880
    },
    {
      "epoch": 2.657608695652174,
      "grad_norm": 1.7747653722763062,
      "learning_rate": 1.6786684782608698e-05,
      "loss": 0.0342,
      "step": 4890
    },
    {
      "epoch": 2.6630434782608696,
      "grad_norm": 0.02289540320634842,
      "learning_rate": 1.671875e-05,
      "loss": 0.0303,
      "step": 4900
    },
    {
      "epoch": 2.6684782608695654,
      "grad_norm": 0.010903139598667622,
      "learning_rate": 1.6650815217391305e-05,
      "loss": 0.0731,
      "step": 4910
    },
    {
      "epoch": 2.6739130434782608,
      "grad_norm": 0.01097937487065792,
      "learning_rate": 1.658288043478261e-05,
      "loss": 0.0415,
      "step": 4920
    },
    {
      "epoch": 2.6793478260869565,
      "grad_norm": 2.1474828720092773,
      "learning_rate": 1.6514945652173912e-05,
      "loss": 0.0314,
      "step": 4930
    },
    {
      "epoch": 2.6847826086956523,
      "grad_norm": 0.01189542654901743,
      "learning_rate": 1.6447010869565217e-05,
      "loss": 0.0527,
      "step": 4940
    },
    {
      "epoch": 2.6902173913043477,
      "grad_norm": 1.5017116069793701,
      "learning_rate": 1.6379076086956522e-05,
      "loss": 0.0309,
      "step": 4950
    },
    {
      "epoch": 2.6956521739130435,
      "grad_norm": 0.020873870700597763,
      "learning_rate": 1.6311141304347828e-05,
      "loss": 0.0219,
      "step": 4960
    },
    {
      "epoch": 2.7010869565217392,
      "grad_norm": 0.01261727511882782,
      "learning_rate": 1.6243206521739133e-05,
      "loss": 0.0186,
      "step": 4970
    },
    {
      "epoch": 2.7065217391304346,
      "grad_norm": 0.008580030873417854,
      "learning_rate": 1.6175271739130435e-05,
      "loss": 0.0207,
      "step": 4980
    },
    {
      "epoch": 2.7119565217391304,
      "grad_norm": 0.009692046791315079,
      "learning_rate": 1.610733695652174e-05,
      "loss": 0.0337,
      "step": 4990
    },
    {
      "epoch": 2.717391304347826,
      "grad_norm": 4.457963943481445,
      "learning_rate": 1.603940217391304e-05,
      "loss": 0.0466,
      "step": 5000
    },
    {
      "epoch": 2.7228260869565215,
      "grad_norm": 0.016241516917943954,
      "learning_rate": 1.5971467391304347e-05,
      "loss": 0.0353,
      "step": 5010
    },
    {
      "epoch": 2.7282608695652173,
      "grad_norm": 0.012911898083984852,
      "learning_rate": 1.5903532608695655e-05,
      "loss": 0.0325,
      "step": 5020
    },
    {
      "epoch": 2.733695652173913,
      "grad_norm": 0.7810051441192627,
      "learning_rate": 1.5835597826086957e-05,
      "loss": 0.0338,
      "step": 5030
    },
    {
      "epoch": 2.7391304347826084,
      "grad_norm": 0.012171381153166294,
      "learning_rate": 1.5767663043478262e-05,
      "loss": 0.0721,
      "step": 5040
    },
    {
      "epoch": 2.744565217391304,
      "grad_norm": 1.9794890880584717,
      "learning_rate": 1.5699728260869568e-05,
      "loss": 0.0447,
      "step": 5050
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.601732850074768,
      "learning_rate": 1.563179347826087e-05,
      "loss": 0.0195,
      "step": 5060
    },
    {
      "epoch": 2.755434782608696,
      "grad_norm": 0.013466191478073597,
      "learning_rate": 1.5563858695652175e-05,
      "loss": 0.0345,
      "step": 5070
    },
    {
      "epoch": 2.7608695652173916,
      "grad_norm": 0.007169874384999275,
      "learning_rate": 1.5495923913043476e-05,
      "loss": 0.0109,
      "step": 5080
    },
    {
      "epoch": 2.766304347826087,
      "grad_norm": 0.016210701316595078,
      "learning_rate": 1.5427989130434785e-05,
      "loss": 0.0604,
      "step": 5090
    },
    {
      "epoch": 2.7717391304347827,
      "grad_norm": 0.00917184166610241,
      "learning_rate": 1.536005434782609e-05,
      "loss": 0.036,
      "step": 5100
    },
    {
      "epoch": 2.7771739130434785,
      "grad_norm": 0.011393530294299126,
      "learning_rate": 1.5292119565217392e-05,
      "loss": 0.0345,
      "step": 5110
    },
    {
      "epoch": 2.782608695652174,
      "grad_norm": 0.422561913728714,
      "learning_rate": 1.5224184782608697e-05,
      "loss": 0.0404,
      "step": 5120
    },
    {
      "epoch": 2.7880434782608696,
      "grad_norm": 1.9177799224853516,
      "learning_rate": 1.5156249999999999e-05,
      "loss": 0.0289,
      "step": 5130
    },
    {
      "epoch": 2.7934782608695654,
      "grad_norm": 0.010122559033334255,
      "learning_rate": 1.5088315217391304e-05,
      "loss": 0.0437,
      "step": 5140
    },
    {
      "epoch": 2.7989130434782608,
      "grad_norm": 0.010964235290884972,
      "learning_rate": 1.5020380434782611e-05,
      "loss": 0.074,
      "step": 5150
    },
    {
      "epoch": 2.8043478260869565,
      "grad_norm": 0.010562026873230934,
      "learning_rate": 1.4952445652173913e-05,
      "loss": 0.0362,
      "step": 5160
    },
    {
      "epoch": 2.8097826086956523,
      "grad_norm": 0.9902385473251343,
      "learning_rate": 1.4884510869565218e-05,
      "loss": 0.0372,
      "step": 5170
    },
    {
      "epoch": 2.8152173913043477,
      "grad_norm": 0.006446681916713715,
      "learning_rate": 1.4816576086956522e-05,
      "loss": 0.0191,
      "step": 5180
    },
    {
      "epoch": 2.8206521739130435,
      "grad_norm": 0.008789479732513428,
      "learning_rate": 1.4748641304347827e-05,
      "loss": 0.0371,
      "step": 5190
    },
    {
      "epoch": 2.8260869565217392,
      "grad_norm": 0.9301047921180725,
      "learning_rate": 1.4680706521739132e-05,
      "loss": 0.0348,
      "step": 5200
    },
    {
      "epoch": 2.8315217391304346,
      "grad_norm": 0.01387583278119564,
      "learning_rate": 1.4612771739130434e-05,
      "loss": 0.0499,
      "step": 5210
    },
    {
      "epoch": 2.8369565217391304,
      "grad_norm": 0.46492254734039307,
      "learning_rate": 1.454483695652174e-05,
      "loss": 0.0349,
      "step": 5220
    },
    {
      "epoch": 2.842391304347826,
      "grad_norm": 1.0496059656143188,
      "learning_rate": 1.4476902173913043e-05,
      "loss": 0.0266,
      "step": 5230
    },
    {
      "epoch": 2.8478260869565215,
      "grad_norm": 0.010353063233196735,
      "learning_rate": 1.4408967391304348e-05,
      "loss": 0.0715,
      "step": 5240
    },
    {
      "epoch": 2.8532608695652173,
      "grad_norm": 0.0064066625200212,
      "learning_rate": 1.4341032608695653e-05,
      "loss": 0.0399,
      "step": 5250
    },
    {
      "epoch": 2.858695652173913,
      "grad_norm": 0.011156491935253143,
      "learning_rate": 1.4273097826086957e-05,
      "loss": 0.0188,
      "step": 5260
    },
    {
      "epoch": 2.8641304347826084,
      "grad_norm": 1.7983615398406982,
      "learning_rate": 1.4205163043478262e-05,
      "loss": 0.0274,
      "step": 5270
    },
    {
      "epoch": 2.869565217391304,
      "grad_norm": 3.987426519393921,
      "learning_rate": 1.4137228260869567e-05,
      "loss": 0.0437,
      "step": 5280
    },
    {
      "epoch": 2.875,
      "grad_norm": 0.8204371929168701,
      "learning_rate": 1.406929347826087e-05,
      "loss": 0.0411,
      "step": 5290
    },
    {
      "epoch": 2.880434782608696,
      "grad_norm": 0.7016247510910034,
      "learning_rate": 1.4001358695652176e-05,
      "loss": 0.0251,
      "step": 5300
    },
    {
      "epoch": 2.8858695652173916,
      "grad_norm": 0.01281961239874363,
      "learning_rate": 1.3933423913043477e-05,
      "loss": 0.0183,
      "step": 5310
    },
    {
      "epoch": 2.891304347826087,
      "grad_norm": 2.3564188480377197,
      "learning_rate": 1.3865489130434783e-05,
      "loss": 0.0655,
      "step": 5320
    },
    {
      "epoch": 2.8967391304347827,
      "grad_norm": 1.3640506267547607,
      "learning_rate": 1.379755434782609e-05,
      "loss": 0.0178,
      "step": 5330
    },
    {
      "epoch": 2.9021739130434785,
      "grad_norm": 2.358327865600586,
      "learning_rate": 1.3729619565217391e-05,
      "loss": 0.0496,
      "step": 5340
    },
    {
      "epoch": 2.907608695652174,
      "grad_norm": 0.010466418229043484,
      "learning_rate": 1.3661684782608697e-05,
      "loss": 0.0287,
      "step": 5350
    },
    {
      "epoch": 2.9130434782608696,
      "grad_norm": 0.010207893326878548,
      "learning_rate": 1.359375e-05,
      "loss": 0.0301,
      "step": 5360
    },
    {
      "epoch": 2.9184782608695654,
      "grad_norm": 2.2141311168670654,
      "learning_rate": 1.3525815217391305e-05,
      "loss": 0.0472,
      "step": 5370
    },
    {
      "epoch": 2.9239130434782608,
      "grad_norm": 1.5004955530166626,
      "learning_rate": 1.345788043478261e-05,
      "loss": 0.0466,
      "step": 5380
    },
    {
      "epoch": 2.9293478260869565,
      "grad_norm": 0.007542426697909832,
      "learning_rate": 1.3389945652173912e-05,
      "loss": 0.0323,
      "step": 5390
    },
    {
      "epoch": 2.9347826086956523,
      "grad_norm": 0.00644993782043457,
      "learning_rate": 1.332201086956522e-05,
      "loss": 0.0366,
      "step": 5400
    },
    {
      "epoch": 2.9402173913043477,
      "grad_norm": 1.265249252319336,
      "learning_rate": 1.3254076086956521e-05,
      "loss": 0.0226,
      "step": 5410
    },
    {
      "epoch": 2.9456521739130435,
      "grad_norm": 0.0143864955753088,
      "learning_rate": 1.3186141304347826e-05,
      "loss": 0.0221,
      "step": 5420
    },
    {
      "epoch": 2.9510869565217392,
      "grad_norm": 0.008918448351323605,
      "learning_rate": 1.3118206521739131e-05,
      "loss": 0.0336,
      "step": 5430
    },
    {
      "epoch": 2.9565217391304346,
      "grad_norm": 0.014407324604690075,
      "learning_rate": 1.3050271739130435e-05,
      "loss": 0.0202,
      "step": 5440
    },
    {
      "epoch": 2.9619565217391304,
      "grad_norm": 3.791287899017334,
      "learning_rate": 1.298233695652174e-05,
      "loss": 0.0399,
      "step": 5450
    },
    {
      "epoch": 2.967391304347826,
      "grad_norm": 0.007869051769375801,
      "learning_rate": 1.2914402173913042e-05,
      "loss": 0.0447,
      "step": 5460
    },
    {
      "epoch": 2.9728260869565215,
      "grad_norm": 1.102968692779541,
      "learning_rate": 1.2846467391304349e-05,
      "loss": 0.0301,
      "step": 5470
    },
    {
      "epoch": 2.9782608695652173,
      "grad_norm": 0.014634449034929276,
      "learning_rate": 1.2778532608695654e-05,
      "loss": 0.0207,
      "step": 5480
    },
    {
      "epoch": 2.983695652173913,
      "grad_norm": 0.03428606688976288,
      "learning_rate": 1.2710597826086956e-05,
      "loss": 0.0259,
      "step": 5490
    },
    {
      "epoch": 2.9891304347826084,
      "grad_norm": 1.6341873407363892,
      "learning_rate": 1.2642663043478261e-05,
      "loss": 0.0186,
      "step": 5500
    },
    {
      "epoch": 2.994565217391304,
      "grad_norm": 0.7299705743789673,
      "learning_rate": 1.2574728260869568e-05,
      "loss": 0.0431,
      "step": 5510
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.9750200510025024,
      "learning_rate": 1.250679347826087e-05,
      "loss": 0.0233,
      "step": 5520
    },
    {
      "epoch": 3.005434782608696,
      "grad_norm": 0.010177799500524998,
      "learning_rate": 1.2438858695652173e-05,
      "loss": 0.0383,
      "step": 5530
    },
    {
      "epoch": 3.010869565217391,
      "grad_norm": 0.013860871084034443,
      "learning_rate": 1.2370923913043478e-05,
      "loss": 0.0398,
      "step": 5540
    },
    {
      "epoch": 3.016304347826087,
      "grad_norm": 0.009225383400917053,
      "learning_rate": 1.2302989130434784e-05,
      "loss": 0.022,
      "step": 5550
    },
    {
      "epoch": 3.0217391304347827,
      "grad_norm": 2.0602192878723145,
      "learning_rate": 1.2235054347826087e-05,
      "loss": 0.0362,
      "step": 5560
    },
    {
      "epoch": 3.027173913043478,
      "grad_norm": 0.268972784280777,
      "learning_rate": 1.216711956521739e-05,
      "loss": 0.0227,
      "step": 5570
    },
    {
      "epoch": 3.032608695652174,
      "grad_norm": 0.009678086265921593,
      "learning_rate": 1.2099184782608698e-05,
      "loss": 0.0312,
      "step": 5580
    },
    {
      "epoch": 3.0380434782608696,
      "grad_norm": 0.01662360318005085,
      "learning_rate": 1.2031250000000001e-05,
      "loss": 0.035,
      "step": 5590
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 0.01353588979691267,
      "learning_rate": 1.1963315217391305e-05,
      "loss": 0.0241,
      "step": 5600
    },
    {
      "epoch": 3.0489130434782608,
      "grad_norm": 0.011087596416473389,
      "learning_rate": 1.189538043478261e-05,
      "loss": 0.028,
      "step": 5610
    },
    {
      "epoch": 3.0543478260869565,
      "grad_norm": 3.092268228530884,
      "learning_rate": 1.1827445652173913e-05,
      "loss": 0.0636,
      "step": 5620
    },
    {
      "epoch": 3.0597826086956523,
      "grad_norm": 0.005837443750351667,
      "learning_rate": 1.1759510869565218e-05,
      "loss": 0.0209,
      "step": 5630
    },
    {
      "epoch": 3.0652173913043477,
      "grad_norm": 0.011910919100046158,
      "learning_rate": 1.1691576086956522e-05,
      "loss": 0.0328,
      "step": 5640
    },
    {
      "epoch": 3.0706521739130435,
      "grad_norm": 1.425290584564209,
      "learning_rate": 1.1623641304347827e-05,
      "loss": 0.0396,
      "step": 5650
    },
    {
      "epoch": 3.0760869565217392,
      "grad_norm": 2.7741191387176514,
      "learning_rate": 1.155570652173913e-05,
      "loss": 0.0664,
      "step": 5660
    },
    {
      "epoch": 3.0815217391304346,
      "grad_norm": 1.5907942056655884,
      "learning_rate": 1.1487771739130436e-05,
      "loss": 0.0666,
      "step": 5670
    },
    {
      "epoch": 3.0869565217391304,
      "grad_norm": 1.5463918447494507,
      "learning_rate": 1.141983695652174e-05,
      "loss": 0.0493,
      "step": 5680
    },
    {
      "epoch": 3.092391304347826,
      "grad_norm": 0.01072497945278883,
      "learning_rate": 1.1351902173913045e-05,
      "loss": 0.0413,
      "step": 5690
    },
    {
      "epoch": 3.097826086956522,
      "grad_norm": 1.0520260334014893,
      "learning_rate": 1.1283967391304348e-05,
      "loss": 0.0284,
      "step": 5700
    },
    {
      "epoch": 3.1032608695652173,
      "grad_norm": 0.010714411735534668,
      "learning_rate": 1.1216032608695652e-05,
      "loss": 0.0497,
      "step": 5710
    },
    {
      "epoch": 3.108695652173913,
      "grad_norm": 0.009716358967125416,
      "learning_rate": 1.1148097826086957e-05,
      "loss": 0.0516,
      "step": 5720
    },
    {
      "epoch": 3.114130434782609,
      "grad_norm": 0.5799497365951538,
      "learning_rate": 1.1080163043478262e-05,
      "loss": 0.0063,
      "step": 5730
    },
    {
      "epoch": 3.119565217391304,
      "grad_norm": 1.9344215393066406,
      "learning_rate": 1.1012228260869566e-05,
      "loss": 0.0689,
      "step": 5740
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.01434132270514965,
      "learning_rate": 1.0944293478260869e-05,
      "loss": 0.0154,
      "step": 5750
    },
    {
      "epoch": 3.130434782608696,
      "grad_norm": 1.506669521331787,
      "learning_rate": 1.0876358695652174e-05,
      "loss": 0.0418,
      "step": 5760
    },
    {
      "epoch": 3.135869565217391,
      "grad_norm": 1.1020383834838867,
      "learning_rate": 1.080842391304348e-05,
      "loss": 0.0552,
      "step": 5770
    },
    {
      "epoch": 3.141304347826087,
      "grad_norm": 0.011406855657696724,
      "learning_rate": 1.0740489130434783e-05,
      "loss": 0.0318,
      "step": 5780
    },
    {
      "epoch": 3.1467391304347827,
      "grad_norm": 2.6110658645629883,
      "learning_rate": 1.0672554347826086e-05,
      "loss": 0.0352,
      "step": 5790
    },
    {
      "epoch": 3.1521739130434785,
      "grad_norm": 1.0671213865280151,
      "learning_rate": 1.0604619565217392e-05,
      "loss": 0.0497,
      "step": 5800
    },
    {
      "epoch": 3.157608695652174,
      "grad_norm": 2.0953547954559326,
      "learning_rate": 1.0536684782608697e-05,
      "loss": 0.0304,
      "step": 5810
    },
    {
      "epoch": 3.1630434782608696,
      "grad_norm": 2.243856191635132,
      "learning_rate": 1.046875e-05,
      "loss": 0.0337,
      "step": 5820
    },
    {
      "epoch": 3.1684782608695654,
      "grad_norm": 0.0069719902239739895,
      "learning_rate": 1.0400815217391306e-05,
      "loss": 0.0492,
      "step": 5830
    },
    {
      "epoch": 3.1739130434782608,
      "grad_norm": 0.00911749992519617,
      "learning_rate": 1.0332880434782609e-05,
      "loss": 0.0308,
      "step": 5840
    },
    {
      "epoch": 3.1793478260869565,
      "grad_norm": 0.8099894523620605,
      "learning_rate": 1.0264945652173913e-05,
      "loss": 0.0306,
      "step": 5850
    },
    {
      "epoch": 3.1847826086956523,
      "grad_norm": 2.82417631149292,
      "learning_rate": 1.0197010869565218e-05,
      "loss": 0.0441,
      "step": 5860
    },
    {
      "epoch": 3.1902173913043477,
      "grad_norm": 0.010938355699181557,
      "learning_rate": 1.0129076086956523e-05,
      "loss": 0.0373,
      "step": 5870
    },
    {
      "epoch": 3.1956521739130435,
      "grad_norm": 0.005897505208849907,
      "learning_rate": 1.0061141304347826e-05,
      "loss": 0.0205,
      "step": 5880
    },
    {
      "epoch": 3.2010869565217392,
      "grad_norm": 0.8833117485046387,
      "learning_rate": 9.99320652173913e-06,
      "loss": 0.0197,
      "step": 5890
    },
    {
      "epoch": 3.2065217391304346,
      "grad_norm": 5.115969657897949,
      "learning_rate": 9.925271739130435e-06,
      "loss": 0.05,
      "step": 5900
    },
    {
      "epoch": 3.2119565217391304,
      "grad_norm": 0.009414506144821644,
      "learning_rate": 9.85733695652174e-06,
      "loss": 0.0483,
      "step": 5910
    },
    {
      "epoch": 3.217391304347826,
      "grad_norm": 2.129361867904663,
      "learning_rate": 9.789402173913044e-06,
      "loss": 0.0343,
      "step": 5920
    },
    {
      "epoch": 3.2228260869565215,
      "grad_norm": 0.511536180973053,
      "learning_rate": 9.721467391304347e-06,
      "loss": 0.0444,
      "step": 5930
    },
    {
      "epoch": 3.2282608695652173,
      "grad_norm": 0.006499643437564373,
      "learning_rate": 9.653532608695653e-06,
      "loss": 0.049,
      "step": 5940
    },
    {
      "epoch": 3.233695652173913,
      "grad_norm": 2.011051893234253,
      "learning_rate": 9.585597826086958e-06,
      "loss": 0.0714,
      "step": 5950
    },
    {
      "epoch": 3.239130434782609,
      "grad_norm": 0.7922890186309814,
      "learning_rate": 9.517663043478261e-06,
      "loss": 0.0365,
      "step": 5960
    },
    {
      "epoch": 3.244565217391304,
      "grad_norm": 0.008820619434118271,
      "learning_rate": 9.449728260869565e-06,
      "loss": 0.0575,
      "step": 5970
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.01385087426751852,
      "learning_rate": 9.38179347826087e-06,
      "loss": 0.0337,
      "step": 5980
    },
    {
      "epoch": 3.255434782608696,
      "grad_norm": 0.010187389329075813,
      "learning_rate": 9.313858695652174e-06,
      "loss": 0.0387,
      "step": 5990
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 0.7952274084091187,
      "learning_rate": 9.245923913043479e-06,
      "loss": 0.0316,
      "step": 6000
    },
    {
      "epoch": 3.266304347826087,
      "grad_norm": 1.9122930765151978,
      "learning_rate": 9.177989130434784e-06,
      "loss": 0.0336,
      "step": 6010
    },
    {
      "epoch": 3.2717391304347827,
      "grad_norm": 0.008425253443419933,
      "learning_rate": 9.110054347826087e-06,
      "loss": 0.043,
      "step": 6020
    },
    {
      "epoch": 3.2771739130434785,
      "grad_norm": 0.7872396111488342,
      "learning_rate": 9.042119565217391e-06,
      "loss": 0.0424,
      "step": 6030
    },
    {
      "epoch": 3.282608695652174,
      "grad_norm": 1.5601818561553955,
      "learning_rate": 8.974184782608696e-06,
      "loss": 0.032,
      "step": 6040
    },
    {
      "epoch": 3.2880434782608696,
      "grad_norm": 0.006069732829928398,
      "learning_rate": 8.906250000000001e-06,
      "loss": 0.0205,
      "step": 6050
    },
    {
      "epoch": 3.2934782608695654,
      "grad_norm": 0.7111182808876038,
      "learning_rate": 8.838315217391305e-06,
      "loss": 0.0331,
      "step": 6060
    },
    {
      "epoch": 3.2989130434782608,
      "grad_norm": 0.006738019175827503,
      "learning_rate": 8.770380434782608e-06,
      "loss": 0.0341,
      "step": 6070
    },
    {
      "epoch": 3.3043478260869565,
      "grad_norm": 0.010885949246585369,
      "learning_rate": 8.702445652173914e-06,
      "loss": 0.032,
      "step": 6080
    },
    {
      "epoch": 3.3097826086956523,
      "grad_norm": 0.014559481292963028,
      "learning_rate": 8.634510869565219e-06,
      "loss": 0.0392,
      "step": 6090
    },
    {
      "epoch": 3.3152173913043477,
      "grad_norm": 2.1122469902038574,
      "learning_rate": 8.566576086956522e-06,
      "loss": 0.0423,
      "step": 6100
    },
    {
      "epoch": 3.3206521739130435,
      "grad_norm": 0.011623735539615154,
      "learning_rate": 8.498641304347826e-06,
      "loss": 0.025,
      "step": 6110
    },
    {
      "epoch": 3.3260869565217392,
      "grad_norm": 0.010650564916431904,
      "learning_rate": 8.430706521739131e-06,
      "loss": 0.0102,
      "step": 6120
    },
    {
      "epoch": 3.3315217391304346,
      "grad_norm": 0.007905054837465286,
      "learning_rate": 8.362771739130436e-06,
      "loss": 0.0348,
      "step": 6130
    },
    {
      "epoch": 3.3369565217391304,
      "grad_norm": 2.210144281387329,
      "learning_rate": 8.29483695652174e-06,
      "loss": 0.0398,
      "step": 6140
    },
    {
      "epoch": 3.342391304347826,
      "grad_norm": 0.013271008618175983,
      "learning_rate": 8.226902173913043e-06,
      "loss": 0.0329,
      "step": 6150
    },
    {
      "epoch": 3.3478260869565215,
      "grad_norm": 1.3430296182632446,
      "learning_rate": 8.158967391304348e-06,
      "loss": 0.0287,
      "step": 6160
    },
    {
      "epoch": 3.3532608695652173,
      "grad_norm": 0.00624519819393754,
      "learning_rate": 8.091032608695652e-06,
      "loss": 0.0445,
      "step": 6170
    },
    {
      "epoch": 3.358695652173913,
      "grad_norm": 0.011643385514616966,
      "learning_rate": 8.023097826086957e-06,
      "loss": 0.0283,
      "step": 6180
    },
    {
      "epoch": 3.364130434782609,
      "grad_norm": 0.01067699957638979,
      "learning_rate": 7.955163043478262e-06,
      "loss": 0.0245,
      "step": 6190
    },
    {
      "epoch": 3.369565217391304,
      "grad_norm": 0.007481342181563377,
      "learning_rate": 7.887228260869566e-06,
      "loss": 0.0124,
      "step": 6200
    },
    {
      "epoch": 3.375,
      "grad_norm": 0.008704441599547863,
      "learning_rate": 7.81929347826087e-06,
      "loss": 0.0123,
      "step": 6210
    },
    {
      "epoch": 3.380434782608696,
      "grad_norm": 1.7992910146713257,
      "learning_rate": 7.751358695652173e-06,
      "loss": 0.0799,
      "step": 6220
    },
    {
      "epoch": 3.385869565217391,
      "grad_norm": 2.0429372787475586,
      "learning_rate": 7.68342391304348e-06,
      "loss": 0.0524,
      "step": 6230
    },
    {
      "epoch": 3.391304347826087,
      "grad_norm": 0.006827744655311108,
      "learning_rate": 7.615489130434783e-06,
      "loss": 0.0258,
      "step": 6240
    },
    {
      "epoch": 3.3967391304347827,
      "grad_norm": 2.404223680496216,
      "learning_rate": 7.547554347826087e-06,
      "loss": 0.0353,
      "step": 6250
    },
    {
      "epoch": 3.4021739130434785,
      "grad_norm": 0.7862686514854431,
      "learning_rate": 7.479619565217391e-06,
      "loss": 0.0233,
      "step": 6260
    },
    {
      "epoch": 3.407608695652174,
      "grad_norm": 2.248728036880493,
      "learning_rate": 7.411684782608696e-06,
      "loss": 0.0206,
      "step": 6270
    },
    {
      "epoch": 3.4130434782608696,
      "grad_norm": 1.475583553314209,
      "learning_rate": 7.343750000000001e-06,
      "loss": 0.0369,
      "step": 6280
    },
    {
      "epoch": 3.4184782608695654,
      "grad_norm": 2.082939624786377,
      "learning_rate": 7.275815217391305e-06,
      "loss": 0.0432,
      "step": 6290
    },
    {
      "epoch": 3.4239130434782608,
      "grad_norm": 0.006785975769162178,
      "learning_rate": 7.2078804347826085e-06,
      "loss": 0.0206,
      "step": 6300
    },
    {
      "epoch": 3.4293478260869565,
      "grad_norm": 0.7360694408416748,
      "learning_rate": 7.139945652173913e-06,
      "loss": 0.0229,
      "step": 6310
    },
    {
      "epoch": 3.4347826086956523,
      "grad_norm": 0.023741155862808228,
      "learning_rate": 7.072010869565218e-06,
      "loss": 0.0401,
      "step": 6320
    },
    {
      "epoch": 3.4402173913043477,
      "grad_norm": 3.1673836708068848,
      "learning_rate": 7.004076086956522e-06,
      "loss": 0.0492,
      "step": 6330
    },
    {
      "epoch": 3.4456521739130435,
      "grad_norm": 0.00812710914760828,
      "learning_rate": 6.936141304347826e-06,
      "loss": 0.0276,
      "step": 6340
    },
    {
      "epoch": 3.4510869565217392,
      "grad_norm": 2.7739875316619873,
      "learning_rate": 6.86820652173913e-06,
      "loss": 0.0445,
      "step": 6350
    },
    {
      "epoch": 3.4565217391304346,
      "grad_norm": 0.007944175973534584,
      "learning_rate": 6.8002717391304355e-06,
      "loss": 0.0312,
      "step": 6360
    },
    {
      "epoch": 3.4619565217391304,
      "grad_norm": 2.4699559211730957,
      "learning_rate": 6.73233695652174e-06,
      "loss": 0.0504,
      "step": 6370
    },
    {
      "epoch": 3.467391304347826,
      "grad_norm": 0.009095900692045689,
      "learning_rate": 6.664402173913044e-06,
      "loss": 0.0305,
      "step": 6380
    },
    {
      "epoch": 3.4728260869565215,
      "grad_norm": 1.5337947607040405,
      "learning_rate": 6.596467391304348e-06,
      "loss": 0.0528,
      "step": 6390
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 0.009179455228149891,
      "learning_rate": 6.528532608695652e-06,
      "loss": 0.0324,
      "step": 6400
    },
    {
      "epoch": 3.483695652173913,
      "grad_norm": 1.7541733980178833,
      "learning_rate": 6.460597826086957e-06,
      "loss": 0.0358,
      "step": 6410
    },
    {
      "epoch": 3.489130434782609,
      "grad_norm": 0.01247057132422924,
      "learning_rate": 6.392663043478262e-06,
      "loss": 0.0464,
      "step": 6420
    },
    {
      "epoch": 3.494565217391304,
      "grad_norm": 1.5881376266479492,
      "learning_rate": 6.324728260869565e-06,
      "loss": 0.023,
      "step": 6430
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.0073783923871815205,
      "learning_rate": 6.2567934782608694e-06,
      "loss": 0.0147,
      "step": 6440
    },
    {
      "epoch": 3.505434782608696,
      "grad_norm": 0.010639013722538948,
      "learning_rate": 6.188858695652174e-06,
      "loss": 0.0284,
      "step": 6450
    },
    {
      "epoch": 3.5108695652173916,
      "grad_norm": 0.005463882815092802,
      "learning_rate": 6.120923913043478e-06,
      "loss": 0.021,
      "step": 6460
    },
    {
      "epoch": 3.516304347826087,
      "grad_norm": 0.008280188776552677,
      "learning_rate": 6.052989130434783e-06,
      "loss": 0.0261,
      "step": 6470
    },
    {
      "epoch": 3.5217391304347827,
      "grad_norm": 0.632977306842804,
      "learning_rate": 5.985054347826087e-06,
      "loss": 0.0356,
      "step": 6480
    },
    {
      "epoch": 3.5271739130434785,
      "grad_norm": 0.007280356250703335,
      "learning_rate": 5.917119565217392e-06,
      "loss": 0.0288,
      "step": 6490
    },
    {
      "epoch": 3.532608695652174,
      "grad_norm": 1.842066764831543,
      "learning_rate": 5.8491847826086956e-06,
      "loss": 0.0309,
      "step": 6500
    },
    {
      "epoch": 3.5380434782608696,
      "grad_norm": 2.519902467727661,
      "learning_rate": 5.781250000000001e-06,
      "loss": 0.0449,
      "step": 6510
    },
    {
      "epoch": 3.5434782608695654,
      "grad_norm": 1.2284061908721924,
      "learning_rate": 5.713315217391304e-06,
      "loss": 0.02,
      "step": 6520
    },
    {
      "epoch": 3.5489130434782608,
      "grad_norm": 0.007430546451359987,
      "learning_rate": 5.645380434782609e-06,
      "loss": 0.0368,
      "step": 6530
    },
    {
      "epoch": 3.5543478260869565,
      "grad_norm": 0.7839612364768982,
      "learning_rate": 5.577445652173913e-06,
      "loss": 0.092,
      "step": 6540
    },
    {
      "epoch": 3.5597826086956523,
      "grad_norm": 1.4427886009216309,
      "learning_rate": 5.509510869565217e-06,
      "loss": 0.0227,
      "step": 6550
    },
    {
      "epoch": 3.5652173913043477,
      "grad_norm": 1.7195924520492554,
      "learning_rate": 5.4415760869565225e-06,
      "loss": 0.041,
      "step": 6560
    },
    {
      "epoch": 3.5706521739130435,
      "grad_norm": 0.8524104952812195,
      "learning_rate": 5.373641304347826e-06,
      "loss": 0.0182,
      "step": 6570
    },
    {
      "epoch": 3.5760869565217392,
      "grad_norm": 1.8079347610473633,
      "learning_rate": 5.305706521739131e-06,
      "loss": 0.0447,
      "step": 6580
    },
    {
      "epoch": 3.5815217391304346,
      "grad_norm": 0.5781391859054565,
      "learning_rate": 5.237771739130435e-06,
      "loss": 0.0397,
      "step": 6590
    },
    {
      "epoch": 3.5869565217391304,
      "grad_norm": 1.1227895021438599,
      "learning_rate": 5.16983695652174e-06,
      "loss": 0.021,
      "step": 6600
    },
    {
      "epoch": 3.592391304347826,
      "grad_norm": 0.3267447352409363,
      "learning_rate": 5.1019021739130435e-06,
      "loss": 0.0471,
      "step": 6610
    },
    {
      "epoch": 3.5978260869565215,
      "grad_norm": 0.007446943316608667,
      "learning_rate": 5.033967391304348e-06,
      "loss": 0.0227,
      "step": 6620
    },
    {
      "epoch": 3.6032608695652173,
      "grad_norm": 1.586244821548462,
      "learning_rate": 4.966032608695652e-06,
      "loss": 0.0219,
      "step": 6630
    },
    {
      "epoch": 3.608695652173913,
      "grad_norm": 1.5959101915359497,
      "learning_rate": 4.8980978260869565e-06,
      "loss": 0.0234,
      "step": 6640
    },
    {
      "epoch": 3.6141304347826084,
      "grad_norm": 3.02555513381958,
      "learning_rate": 4.830163043478262e-06,
      "loss": 0.0373,
      "step": 6650
    },
    {
      "epoch": 3.619565217391304,
      "grad_norm": 0.011154248379170895,
      "learning_rate": 4.762228260869565e-06,
      "loss": 0.0302,
      "step": 6660
    },
    {
      "epoch": 3.625,
      "grad_norm": 1.801750659942627,
      "learning_rate": 4.6942934782608704e-06,
      "loss": 0.0219,
      "step": 6670
    },
    {
      "epoch": 3.630434782608696,
      "grad_norm": 0.007794334553182125,
      "learning_rate": 4.626358695652174e-06,
      "loss": 0.025,
      "step": 6680
    },
    {
      "epoch": 3.6358695652173916,
      "grad_norm": 0.01434754952788353,
      "learning_rate": 4.558423913043478e-06,
      "loss": 0.0368,
      "step": 6690
    },
    {
      "epoch": 3.641304347826087,
      "grad_norm": 1.3668400049209595,
      "learning_rate": 4.490489130434783e-06,
      "loss": 0.0464,
      "step": 6700
    },
    {
      "epoch": 3.6467391304347827,
      "grad_norm": 0.946727991104126,
      "learning_rate": 4.422554347826087e-06,
      "loss": 0.0574,
      "step": 6710
    },
    {
      "epoch": 3.6521739130434785,
      "grad_norm": 0.009317751973867416,
      "learning_rate": 4.354619565217391e-06,
      "loss": 0.0504,
      "step": 6720
    },
    {
      "epoch": 3.657608695652174,
      "grad_norm": 0.006311364006251097,
      "learning_rate": 4.286684782608696e-06,
      "loss": 0.0199,
      "step": 6730
    },
    {
      "epoch": 3.6630434782608696,
      "grad_norm": 0.0058245365507900715,
      "learning_rate": 4.218750000000001e-06,
      "loss": 0.0258,
      "step": 6740
    },
    {
      "epoch": 3.6684782608695654,
      "grad_norm": 2.430269956588745,
      "learning_rate": 4.150815217391304e-06,
      "loss": 0.0394,
      "step": 6750
    },
    {
      "epoch": 3.6739130434782608,
      "grad_norm": 0.006912488490343094,
      "learning_rate": 4.082880434782609e-06,
      "loss": 0.0332,
      "step": 6760
    },
    {
      "epoch": 3.6793478260869565,
      "grad_norm": 1.685641884803772,
      "learning_rate": 4.014945652173913e-06,
      "loss": 0.0278,
      "step": 6770
    },
    {
      "epoch": 3.6847826086956523,
      "grad_norm": 0.006526118144392967,
      "learning_rate": 3.9470108695652175e-06,
      "loss": 0.0517,
      "step": 6780
    },
    {
      "epoch": 3.6902173913043477,
      "grad_norm": 0.007397499866783619,
      "learning_rate": 3.879076086956522e-06,
      "loss": 0.0035,
      "step": 6790
    },
    {
      "epoch": 3.6956521739130435,
      "grad_norm": 1.9596991539001465,
      "learning_rate": 3.811141304347826e-06,
      "loss": 0.0357,
      "step": 6800
    },
    {
      "epoch": 3.7010869565217392,
      "grad_norm": 1.248685359954834,
      "learning_rate": 3.743206521739131e-06,
      "loss": 0.0214,
      "step": 6810
    },
    {
      "epoch": 3.7065217391304346,
      "grad_norm": 0.7564817667007446,
      "learning_rate": 3.675271739130435e-06,
      "loss": 0.0333,
      "step": 6820
    },
    {
      "epoch": 3.7119565217391304,
      "grad_norm": 1.4580870866775513,
      "learning_rate": 3.6073369565217397e-06,
      "loss": 0.0332,
      "step": 6830
    },
    {
      "epoch": 3.717391304347826,
      "grad_norm": 1.6531357765197754,
      "learning_rate": 3.5394021739130436e-06,
      "loss": 0.0522,
      "step": 6840
    },
    {
      "epoch": 3.7228260869565215,
      "grad_norm": 2.617216110229492,
      "learning_rate": 3.4714673913043475e-06,
      "loss": 0.0334,
      "step": 6850
    },
    {
      "epoch": 3.7282608695652173,
      "grad_norm": 0.0074855671264231205,
      "learning_rate": 3.4035326086956523e-06,
      "loss": 0.0326,
      "step": 6860
    },
    {
      "epoch": 3.733695652173913,
      "grad_norm": 0.009064784273505211,
      "learning_rate": 3.3355978260869567e-06,
      "loss": 0.0544,
      "step": 6870
    },
    {
      "epoch": 3.7391304347826084,
      "grad_norm": 2.4657347202301025,
      "learning_rate": 3.2676630434782614e-06,
      "loss": 0.0243,
      "step": 6880
    },
    {
      "epoch": 3.744565217391304,
      "grad_norm": 1.7630259990692139,
      "learning_rate": 3.1997282608695654e-06,
      "loss": 0.0274,
      "step": 6890
    },
    {
      "epoch": 3.75,
      "grad_norm": 1.282315969467163,
      "learning_rate": 3.13179347826087e-06,
      "loss": 0.0356,
      "step": 6900
    },
    {
      "epoch": 3.755434782608696,
      "grad_norm": 1.8737845420837402,
      "learning_rate": 3.063858695652174e-06,
      "loss": 0.0364,
      "step": 6910
    },
    {
      "epoch": 3.7608695652173916,
      "grad_norm": 1.9672929048538208,
      "learning_rate": 2.9959239130434784e-06,
      "loss": 0.0308,
      "step": 6920
    },
    {
      "epoch": 3.766304347826087,
      "grad_norm": 2.1598315238952637,
      "learning_rate": 2.9279891304347828e-06,
      "loss": 0.0355,
      "step": 6930
    },
    {
      "epoch": 3.7717391304347827,
      "grad_norm": 0.34794288873672485,
      "learning_rate": 2.860054347826087e-06,
      "loss": 0.0327,
      "step": 6940
    },
    {
      "epoch": 3.7771739130434785,
      "grad_norm": 0.005865123588591814,
      "learning_rate": 2.7921195652173915e-06,
      "loss": 0.0206,
      "step": 6950
    },
    {
      "epoch": 3.782608695652174,
      "grad_norm": 1.616368293762207,
      "learning_rate": 2.724184782608696e-06,
      "loss": 0.0593,
      "step": 6960
    },
    {
      "epoch": 3.7880434782608696,
      "grad_norm": 1.6436201333999634,
      "learning_rate": 2.65625e-06,
      "loss": 0.0377,
      "step": 6970
    },
    {
      "epoch": 3.7934782608695654,
      "grad_norm": 0.012199120596051216,
      "learning_rate": 2.5883152173913045e-06,
      "loss": 0.0329,
      "step": 6980
    },
    {
      "epoch": 3.7989130434782608,
      "grad_norm": 1.6205500364303589,
      "learning_rate": 2.520380434782609e-06,
      "loss": 0.046,
      "step": 6990
    },
    {
      "epoch": 3.8043478260869565,
      "grad_norm": 1.8784013986587524,
      "learning_rate": 2.4524456521739133e-06,
      "loss": 0.0355,
      "step": 7000
    },
    {
      "epoch": 3.8097826086956523,
      "grad_norm": 2.167865037918091,
      "learning_rate": 2.3845108695652176e-06,
      "loss": 0.0206,
      "step": 7010
    },
    {
      "epoch": 3.8152173913043477,
      "grad_norm": 0.006698227487504482,
      "learning_rate": 2.316576086956522e-06,
      "loss": 0.0281,
      "step": 7020
    },
    {
      "epoch": 3.8206521739130435,
      "grad_norm": 2.147160768508911,
      "learning_rate": 2.248641304347826e-06,
      "loss": 0.0231,
      "step": 7030
    },
    {
      "epoch": 3.8260869565217392,
      "grad_norm": 0.008765913546085358,
      "learning_rate": 2.1807065217391302e-06,
      "loss": 0.0368,
      "step": 7040
    },
    {
      "epoch": 3.8315217391304346,
      "grad_norm": 2.1338751316070557,
      "learning_rate": 2.112771739130435e-06,
      "loss": 0.0376,
      "step": 7050
    },
    {
      "epoch": 3.8369565217391304,
      "grad_norm": 1.673827886581421,
      "learning_rate": 2.0448369565217394e-06,
      "loss": 0.0217,
      "step": 7060
    },
    {
      "epoch": 3.842391304347826,
      "grad_norm": 0.00742532592266798,
      "learning_rate": 1.9769021739130437e-06,
      "loss": 0.0297,
      "step": 7070
    },
    {
      "epoch": 3.8478260869565215,
      "grad_norm": 0.4447823166847229,
      "learning_rate": 1.908967391304348e-06,
      "loss": 0.0378,
      "step": 7080
    },
    {
      "epoch": 3.8532608695652173,
      "grad_norm": 0.009494894184172153,
      "learning_rate": 1.8410326086956524e-06,
      "loss": 0.0365,
      "step": 7090
    },
    {
      "epoch": 3.858695652173913,
      "grad_norm": 1.5204600095748901,
      "learning_rate": 1.7730978260869568e-06,
      "loss": 0.0287,
      "step": 7100
    },
    {
      "epoch": 3.8641304347826084,
      "grad_norm": 0.003094893181696534,
      "learning_rate": 1.7051630434782607e-06,
      "loss": 0.0475,
      "step": 7110
    },
    {
      "epoch": 3.869565217391304,
      "grad_norm": 0.013611910864710808,
      "learning_rate": 1.6372282608695653e-06,
      "loss": 0.0217,
      "step": 7120
    },
    {
      "epoch": 3.875,
      "grad_norm": 1.3277031183242798,
      "learning_rate": 1.5692934782608696e-06,
      "loss": 0.0219,
      "step": 7130
    },
    {
      "epoch": 3.880434782608696,
      "grad_norm": 0.6992518901824951,
      "learning_rate": 1.501358695652174e-06,
      "loss": 0.035,
      "step": 7140
    },
    {
      "epoch": 3.8858695652173916,
      "grad_norm": 1.8752050399780273,
      "learning_rate": 1.4334239130434783e-06,
      "loss": 0.0227,
      "step": 7150
    },
    {
      "epoch": 3.891304347826087,
      "grad_norm": 0.012837635353207588,
      "learning_rate": 1.3654891304347827e-06,
      "loss": 0.036,
      "step": 7160
    },
    {
      "epoch": 3.8967391304347827,
      "grad_norm": 0.0071561867371201515,
      "learning_rate": 1.297554347826087e-06,
      "loss": 0.0189,
      "step": 7170
    },
    {
      "epoch": 3.9021739130434785,
      "grad_norm": 1.706316590309143,
      "learning_rate": 1.2296195652173914e-06,
      "loss": 0.0529,
      "step": 7180
    },
    {
      "epoch": 3.907608695652174,
      "grad_norm": 1.629282832145691,
      "learning_rate": 1.1616847826086958e-06,
      "loss": 0.0332,
      "step": 7190
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 0.006717713084071875,
      "learning_rate": 1.09375e-06,
      "loss": 0.0271,
      "step": 7200
    },
    {
      "epoch": 3.9184782608695654,
      "grad_norm": 0.006772429682314396,
      "learning_rate": 1.0258152173913045e-06,
      "loss": 0.0333,
      "step": 7210
    },
    {
      "epoch": 3.9239130434782608,
      "grad_norm": 0.005834676790982485,
      "learning_rate": 9.578804347826088e-07,
      "loss": 0.0199,
      "step": 7220
    },
    {
      "epoch": 3.9293478260869565,
      "grad_norm": 0.005923446733504534,
      "learning_rate": 8.899456521739132e-07,
      "loss": 0.0394,
      "step": 7230
    },
    {
      "epoch": 3.9347826086956523,
      "grad_norm": 0.00964888371527195,
      "learning_rate": 8.220108695652173e-07,
      "loss": 0.0262,
      "step": 7240
    },
    {
      "epoch": 3.9402173913043477,
      "grad_norm": 0.008987266570329666,
      "learning_rate": 7.540760869565218e-07,
      "loss": 0.0379,
      "step": 7250
    },
    {
      "epoch": 3.9456521739130435,
      "grad_norm": 0.009400337934494019,
      "learning_rate": 6.861413043478261e-07,
      "loss": 0.0301,
      "step": 7260
    },
    {
      "epoch": 3.9510869565217392,
      "grad_norm": 1.8218050003051758,
      "learning_rate": 6.182065217391305e-07,
      "loss": 0.0487,
      "step": 7270
    },
    {
      "epoch": 3.9565217391304346,
      "grad_norm": 0.011968287639319897,
      "learning_rate": 5.502717391304348e-07,
      "loss": 0.0253,
      "step": 7280
    },
    {
      "epoch": 3.9619565217391304,
      "grad_norm": 1.0439265966415405,
      "learning_rate": 4.823369565217392e-07,
      "loss": 0.0326,
      "step": 7290
    },
    {
      "epoch": 3.967391304347826,
      "grad_norm": 0.006745816674083471,
      "learning_rate": 4.1440217391304355e-07,
      "loss": 0.0361,
      "step": 7300
    },
    {
      "epoch": 3.9728260869565215,
      "grad_norm": 0.012483726255595684,
      "learning_rate": 3.4646739130434785e-07,
      "loss": 0.0434,
      "step": 7310
    },
    {
      "epoch": 3.9782608695652173,
      "grad_norm": 1.7697701454162598,
      "learning_rate": 2.785326086956522e-07,
      "loss": 0.0264,
      "step": 7320
    },
    {
      "epoch": 3.983695652173913,
      "grad_norm": 0.4782308042049408,
      "learning_rate": 2.1059782608695653e-07,
      "loss": 0.0473,
      "step": 7330
    },
    {
      "epoch": 3.9891304347826084,
      "grad_norm": 0.010100796818733215,
      "learning_rate": 1.4266304347826088e-07,
      "loss": 0.0206,
      "step": 7340
    },
    {
      "epoch": 3.994565217391304,
      "grad_norm": 0.007288054097443819,
      "learning_rate": 7.472826086956522e-08,
      "loss": 0.0372,
      "step": 7350
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.01339662354439497,
      "learning_rate": 6.7934782608695654e-09,
      "loss": 0.0253,
      "step": 7360
    }
  ],
  "logging_steps": 10,
  "max_steps": 7360,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3907610687545344.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
